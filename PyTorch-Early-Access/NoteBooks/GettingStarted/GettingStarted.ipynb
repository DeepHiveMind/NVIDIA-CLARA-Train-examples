{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Getting started with Clara Train SDK V4.0 PyTorch using MONAI \nClara Train SDK consists of different modules as shown below \n\u003cbr\u003e![side_bar](screenShots/TrainBlock.png)\n\nClara Train SDK simply allows researcher to train AI models using configuration files. \nIt is simple to use, modular and flexible. Allowing researchers to focus on innovation, \nwhile leaving acceleration and performance issue for NVIDIA\u0027s engineers \n   \nBy the end of this notebook you will:\n1. Understand components of [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/mmar.html)\n2. Know how to configure train config json to train a CNN\n3. Train a CNN with single and multiple GPUs\n4. Fine tune a model\n5. Export a model \n6. Perform inference on testing dataset \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Prerequisites\n- Nvidia GPU with 8Gb of memory   ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Resources\nYou could watch the free GTC 2020 talks covering Clara Train SDK \n- [S22563](https://developer.nvidia.com/gtc/2020/video/S22563)\nClara train Getting started: cover basics, BYOC, AIAA, AutoML \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Background\n\nClara Train is built using a component-based architecture with using components from [MONAI](https://monai.io/) :\nMONAI’s [training workflows](https://docs.monai.io/en/latest/highlights.html#workflows) \nare based off of [PyTorch Ignite’s engine](https://pytorch.org/ignite/engine.html). \nBelow is a list of different components used:\n- Training Data Pipeline\n- Validation Data Pipeline\n- [Applications](https://docs.monai.io/en/latest/apps.html)\n- [Transforms](https://docs.monai.io/en/latest/transforms.html)\n- [Data](https://docs.monai.io/en/latest/data.html)\n- [Engines](https://docs.monai.io/en/latest/engines.html)\n- [Inference methods](https://docs.monai.io/en/latest/inferers.html)\n- [Event handlers](https://docs.monai.io/en/latest/handlers.html)\n- [Network architectures](https://docs.monai.io/en/latest/networks.html)\n- [Loss functions](https://docs.monai.io/en/latest/losses.html)\n- [Optimizers](https://docs.monai.io/en/latest/optimizers.html)\n- [Metrics](https://docs.monai.io/en/latest/metrics.html)\n- [Visualizations](https://docs.monai.io/en/latest/visualize.html)\n- [Utilities](https://docs.monai.io/en/latest/utils.html)   \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Lets get started\nBefore we get started lets check that we have an NVIDIA GPU available in the docker by running the cell below",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# following command should show all gpus available \n!nvidia-smi",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Next cell defines functions that we will use throughout the notebook",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "MMAR_ROOT\u003d\"/claraDevDay/GettingStarted/\"\nprint (\"setting MMAR_ROOT\u003d\",MMAR_ROOT)\n%ls $MMAR_ROOT\n\n!chmod 777 $MMAR_ROOT/commands/*\ndef printFile(filePath,lnSt,lnEnd):\n    print (\"showing \",str(lnOffset),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n    # lnEnd\u003dlnSt+lnOffset\n    !\u003c $filePath head -n \"$lnEnd\" | tail -n +\"$lnSt\"\n ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Medical Model ARchive (MMAR)\nClara Train SDK uses the [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/mmar.html). \nThe MMAR defines a standard structure for organizing all artifacts produced during the model development life cycle. \nClara Train SDK simple basic idea is to train using config file as shown below\n\u003cbr\u003e![side_bar](screenShots/MMAR.png)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can download sample models for different problems from [NGC](https://ngc.nvidia.com/catalog/models?orderBy\u003dmodifiedDESC\u0026pageNumber\u003d0\u0026query\u003dclara\u0026quickFilter\u003d\u0026filters\u003d) \u003cbr\u003e \nAll MMAR follow the structure provided in this Notebook. if you navigate to the parent folder structure it should contain the following subdirectories\n```\n./GettingStarted \n├── commands\n├── config\n├── docs\n├── eval\n├── models\n└── resources\n```\n\n* `commands` contains a number of ready-to-run scripts for:\n    - training\n    - training with multiple GPU\n    - validation\n    - inference (testing)\n    - exporting models in TensorRT Inference Server format\n* `config` contains configuration files (in JSON format) for eac training, \nvalidation, and deployment for [AI-assisted annotation](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/aiaa/index.html) \n(_Note:_ these configuration files are used in the scripts under the `commands` folder)\n* `docs` contains local documentation for the model, but for a more complete view it is recommended you visit the NGC model page\n* `eval` is used as the output directory for model evaluation (by default)\n* `models` is where the PyTorch checkpoint model is stored, and the corresponding graph definition files.\n* `resources` currently contains the logger configuration in `log.config` file\n\nSome of the most important files you will need to understand to configure and use Clara Train SDK are\n\n1. `environment.json` which has important common parameters to set the path for \n    * `DATA_ROOT` is the root folder where the data with which we would like to train, validate, or test resides in\n    * `DATASET_JSON` expects the path to a JSON-formatted file \n    * `MMAR_CKPT_DIR` the path to the where the PyTorch checkpoint files reside\n    * `MMAR_EVAL_OUTPUT_PATH` the path to output evaluation metrics for the neural network during training, validation, and inference\n    * `PROCESSING_TASK` the type of processing task the neural net is intended to perform (currently limited to `annotation`, `segmentation`, `classification`)\n    * `PRETRAIN_WEIGHTS_FILE` (_optional_) \tdetermines the location of the pre-trained weights file; if the file does not exist and is needed, \n    the training program will download it from predefined URL from the web\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/config/environment.json\",0,30)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Config.json Main Concepts ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n`config_train.json` contains all the parameters necessary to define the neural net, \nhow is it trained (training hyper-parameters, loss, etc.), \npre- and post-transformation functions necessary to modify and/or augment the data before input to the neural net, etc. \nThe complete documentation on the training configuration is laid out \n[here](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/appendix/configuration.html#training-configuration).\nConfiguration file defines all training related configurations. \nThis is were most the researcher would spent most of his time.\n\n\u003cbr\u003e![s](screenShots/MMARParts.png)\u003cbr\u003e \n\nLets take some time to examine each part of it.  \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Global configurations ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    \"model\": {\n",
            "      \"name\": \"Unet\",\n",
            "      \"args\": {\n",
            "        \"num_classes\": 6,\n",
            "        \"nf_enc\":\"32,64,64,64\",\n",
            "        \"nf_dec\":\"64,64,64,64,64,32,32\"\n",
            "      }\n",
            "    },\n",
            "    \"pre_transforms\": [\n",
            "      {\n",
            "        \"name\": \"LoadNifti\",\n"
          ]
        }
      ],
      "source": "confFile\u003dMMAR_ROOT+\"/config/config_train_Unet.json\"\nprintFile(confFile,0,9)\n"
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Training configurations section \nThis section includes:\n1. Loss functions:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,9,17)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n2. Optimizer",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,17,23)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n3. Learning rate scheduler",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,23,30)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n4. Network architecture",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,30,42)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n5. Pre-transforms\n    1. Loading transformations:\n    2. Resample Transformation\n    3. Cropping transformations\n    4. Deformable transformations\n    5. Intensity Transforms\n    6. Augmentation Transforms\n    7. Special transforms ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,42,118)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n6. DataSet to use ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,118,129)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n7. DataLoader",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,129,137)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n8. inferer",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,137,140)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n9. Handlers",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,140,182)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n10. Post transforms\n    1. Loading transformations:\n    2. Resample Transformation\n    3. Cropping transformations\n    4. Deformable transformations\n    5. Intensity Transforms\n    6. Augmentation Transforms\n    7. Special transforms ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,182,200)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "11. Metric",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,200,210)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 3. Validation config \nThis contains sub sections very similar to the ones in the training section including:\n1. Metric \n2. pre-transforms. Since these transforms are usually a subset from teh pre-transforms in the training section, \nwe can use the alias to point to these transforms by name as ` \"ref\": \"LoadNifti\"`. \nIn case we use 2 transforms with the same name as `ScaleByResolution` \nwe can give each an alias to refer to as `\"name\": \"ScaleByResolution#ScaleImg\"` \nthen refer to it in the validation section as `ScaleImg` \n3. Image pipeline\n4. Inference",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(confFile,214,250)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Training your first Network",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Start TensorBoard \nBefore we start training or while the network is training, \nyou can monitor its accuracy using tensorboard in side jupyter lab as shown below \n \u003cbr\u003e\u003cimg src\u003d\"screenShots/TensorBoard.png\" alt\u003d\"Drawing\" style\u003d\"height: 300px;\"/\u003e\u003cbr\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Training script \nWe have renamed `train.sh` to `train_W_Config` as we modified it to accept parameters with the config to use\n\nLet\u0027s take a look at `train_W_Config.sh` by executing the following cell.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/commands/train_W_Config.sh\",30,30)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Start training\nNow that we have our training configuration, to start training simply run `train.sh` as below. \nPlease keep in mind that we have setup a dummy data with one file to train a dummy network fast (we only train for 2 epochs). \nPlease see exercises on how to easily switch data and train a real segmentation network.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train_W_Config.sh config_train_Unet.json",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now lets see the `models` directory, which would includes out models and the tensorboard files ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! ls -la $MMAR_ROOT/models/config_train_Unet",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n# Export Model\n\nTo export the model we simply run `export.sh` which will: \n- Removes back propagation information from checkpoint files\n- Generates two frozen graphs in the models folder\nThis optimized model will be used by TRTIS server in Clara Deploy.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/export.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n\nlets check out what was created in the folder. \nafter running cell below you should see `model.ts`\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!ls -la $MMAR_ROOT/models/config_train_Unet/*.ts",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n# Validation \nNow that we have trained our model we would like to run evaluation to get some statistics and also do inference to see the resulted output\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Validate with single GPU \nTo run evaluation on your validation dataset you should run `validate.sh`. \nThis will run evaluation on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the [environment.json](config/environment.json) \nfile (default is eval folder). \nThis evaluation would give min, max, mean of the metric as specified in the config_validation file\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/validate.sh\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Validate with multiple GPUs \nYou can also leverage multi-GPUs for validation using `validate_multi_gpu.sh` ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!$MMAR_ROOT/commands/validate_multi_gpu.sh ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now lets see results in the folder by running cells below. \nYou should see statistics and dice per file in the validation dataset",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! ls -la $MMAR_ROOT/eval/",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# statistic summary\n!cat $MMAR_ROOT/eval/mean_dice_class1_summary_results.txt",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!cat $MMAR_ROOT/eval/mean_dice_class1_raw_results.txt",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Inference  \n\nTo run inference on validation dataset or test dataset you should run `infer.sh`. \nThis will run prediction on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the \n[environment.json](config/environment.json) file (default is eval folder)\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/infer.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now lets see results in the folder",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! ls -la $MMAR_ROOT/eval/",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! ls -la $MMAR_ROOT/eval/spleen_8\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Multi-GPU Training\nClara train aims to simplify scaling and utilizing all available gpus. \nUsing the same config we already used for train we can simply invoke `train_multi_gpu.sh` to train on multiple gpus. \n\nLets examine `train_multi_gpu.sh` script by running cell below. \nYou can see we are changing the learning rate as the batch size has doubled.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/commands/train_multi_gpu.sh\",0,50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Lets give it a try and run cell below to train on 2 gpus",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train_multi_gpu.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n## Training Vs FineTune\n`train.sh` and `finetune.sh` are identical except they train using different configurations files. \n\n_Note_: The only difference between the two configs `config_train_Unet.json` and `config_finetune.json` \nis that `config_finetune.json` specifies a `ckpt` file in section below \nwhile `config_train_Unet.json` does not since it is training from scratch.\n```\n      {\n        \"name\": \"CheckpointLoader\",\n        \"args\": {\n          \"load_path\": \"{MMAR_CKPT}\",\n          \"load_dict\": [\"model\"]\n        }\n      },\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n# Exercise:\nNow that you are familiar with clara train, you can try to: \n1. Explore different options of clara train by changing / creating a new config file and running training: \n    1. Model architecture: Ahnet, Unet, Segresnet \n    2. Losses\n    3. Transformation \nHint: you for training segresnet you can use the configuration `config_train_segresnet.json` that only changed the network section.\nyou can train by running cell below     ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!$MMAR_ROOT/commands/train_W_Config.sh config_train_segresnet.json\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "2. Train on real spleen data for this you should:\n    1. Download spleen dataset by running the [download](../Data/DownloadDecathlonDataSet.ipynb) Notebook\n    2. Switch the dataset file in the [environment.json](config/environment.json)\n    3. rerun the `train.sh`\n3. Experiment with multi-GPU training by changing number of gpus to train on from 2 to 3 or 4. \nYou should edit [train_multi_gpu.sh](commands/train_multi_gpu.sh) then rerun the script \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "4. Use DLprof tool for debugging ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!$MMAR_ROOT/commands/debug_dlprof.sh config_train_Unet_NoAMP.json",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You then need to run tensor board manually (Not through jupyterlab) using \n```\ncd /claraDevDay/GettingStarted/models/config_train_Unet_debug\ntensorboard --logdir ./dlprof --port 80\n```\nremember we startdocker.sh mounted port 80 to 5000 by default for AIAA, we simply are using that mapping here for simplicity \nnow if you navigate to `\u003cyourip:5000\u003e` you should see DlProf tool as below. \nThis analysis shows you the GPUs you have along improvements that you can do to train faster. \nFor example this run shows multiple operations that would be accelerated from AMP.\nTo test this you can run cell below with AMP enabled in the configuration \n\n\u003cbr\u003e![dlprof](screenShots/Dlprof.png)\u003cbr\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "!$MMAR_ROOT/commands/debug_dlprof.sh config_train_Unet.json\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}