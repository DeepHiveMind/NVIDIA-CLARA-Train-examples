{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# \u003ccenter\u003eNotebook for Digital Pathology on Clara Train SDK \n\n## Description\nClara Train SDK comes with many models for different tasks. \nThis notebook will go through the usecase of automated detection of metastases from histopathology whole slide images (WSIs).\nThis notebooks walks you throug :\n1. Downloading the data\n2. preprocessing the labels\n3. Introducing [cuCIM](https://github.com/rapidsai/cucim/), an extensible toolkit designed to provide GPU accelerated I/O to load WSI images.\n4. Training a model \n5. Inferring \n"
    },
    {
      "cell_type": "markdown",
      "source": "## Method Settings\nAll the data used to train, validate, and test this model is from \n[Camelyon-16 Challenge](https://camelyon16.grand-challenge.org/).\n\nThe detection task is formulated as classification: determining if an arbitary 224x224x3 RGB patch sampled from the WSI is tumor or normal.\n\nWe adopted [NCRF](https://github.com/baidu-research/NCRF) method\u0027s way of patch sampling, please refer to the corresponding website for more information.\n\nTraining is performed on patch-label pairs, which are sampled from WSI with tumor delineations.  \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/workflow.png\" width\u003d\"600\"/\u003e\u003c/left\u003e\n\nThe prediction map is generated in a sliding-window manner.  \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/prediction.png\" width\u003d\"300\"/\u003e \u003cimg src\u003d\"screenShots/image.png\" width\u003d\"300\" align\u003d\"left\"/\u003e\u003c/left\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Disclamer \nThis notebook will use four WSI files to illustrate the training process.\nThis is **ONLY** intended to show the user how to get started. \nFor the model please train on full data (download process can take several days), or download the trained model from NGC release. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Prerequisites\n- Familiarity with Clara Train main concepts. See [Getting Started Notebook](../../GettingStarted/GettingStarted.ipynb)\n- Familiarity with Bring your own component. See [GBring your own component notebook](../../GettingStarted/BYOC.ipynb)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## \u003ccenter\u003eNow Let\u0027s Get Started with Data Preparation and Clara Pathology Detection MMAR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 1. Download Data\n",
        "First let\u0027s setup directories for the data, this will create /Data folder in the current path, with all necessary subfolders "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data dir root:  /workspace/Pathology/Data/\n"
          ]
        }
      ],
      "source": "import os\nroot\u003dos.getcwd()\n# DataDirRoot\u003droot+\"/Data/\"\nDataDirRoot\u003d\"/claraDevDay/Data/DP_CAMELYON16/\"\nprint(\"Data dir root: \", DataDirRoot)\n\nDataDirJson\u003dDataDirRoot+\"jsons/\"\nDataDirCoordRaw\u003dDataDirRoot+\"coordsRaw/\"\nDataDirCoord\u003dDataDirRoot+\"coords/\"\nDataDirWSI\u003dDataDirRoot+\"WSI/\"\nDataDirLoc\u003dDataDirRoot+\"LocLabel/\"\n\nos.makedirs(DataDirJson, exist_ok\u003dTrue)\nos.makedirs(DataDirCoordRaw, exist_ok\u003dTrue)\nos.makedirs(DataDirCoord, exist_ok\u003dTrue)\nos.makedirs(DataDirWSI, exist_ok\u003dTrue)\nos.makedirs(DataDirLoc, exist_ok\u003dTrue)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "To be specific, below folder will be downloaded\n- /WSI stores the histopathology images\n- /jsons stores the ground truth annotation in json format\n- /coordsRaw stores all patch sample locations\n\u003cbr\u003e\nbelow folders would be generated:\n- /coords will be generated from /coordsRaw by keeping only the locations for the downloaded WSIs (4 in this notebook).\n- /LocLabel contains the full sample info, and will be generated based on /coords and /jsons  \n\u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/folders.png\" width\u003d\"200\"/\u003e\u003c/left\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### 1.1 Download WSIs  \n",
        "You can download all the images for \"CAMELYON16 data set\" from various sources listed \n",
        "[here](https://camelyon17.grand-challenge.org/Data/). Downloading all data can take several days.\n",
        "\n",
        "Due to time constraint and for simplicity, this notebook only download 4 WSIs: 2 tumors and 2 normals for training and validation respectively. Let\u0027s download them from FTP below. \u003cbr\u003e\n",
        "**Please note: This download could take some time, in total 3.3 GB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting progressbar2\n",
            "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting python-utils\u003e\u003d2.3.0\n",
            "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from progressbar2) (1.15.0)\n",
            "Installing collected packages: python-utils, progressbar2\n",
            "Successfully installed progressbar2-3.53.1 python-utils-2.5.6\n",
            "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
            "You should consider upgrading via the \u0027/opt/conda/bin/python -m pip install --upgrade pip\u0027 command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install progressbar2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from progressbar import ProgressBar, Percentage, Bar, ETA, FileTransferSpeed\n",
        "def download_file_with_progressbar(data):\n",
        "    f.write(data) \n",
        "    global bar\n",
        "    bar +\u003d len(data)\n",
        "\n",
        "import ftplib\n",
        "import os\n",
        "def download_camelyon16_image(filename):\n",
        "    filename \u003d filename.lower()\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"The image [{filename}] already exist locally.\")\n",
        "    else:\n",
        "        print(f\"Downloading \u0027{filename}\u0027...\")\n",
        "        prefix \u003d filename.split(\"_\")[0].lower()\n",
        "        if prefix \u003d\u003d \"test\":\n",
        "            folder_name \u003d \"testing/images\"\n",
        "        elif prefix in [\"normal\", \"tumor\"]:\n",
        "            folder_name \u003d f\"training/{prefix}\"\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"\u0027{filename}\u0027 not found on the server.\"\n",
        "                \" File name should be like \u0027test_001.tif\u0027, \u0027tumor_001.tif\u0027, or \u0027normal_001.tif\u0027\"\n",
        "            )\n",
        "        path \u003d f\"gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/{folder_name}/\"\n",
        "        ftp \u003d ftplib.FTP(\"parrot.genomics.cn\")\n",
        "        ftp.login(\"anonymous\", \"\")\n",
        "        filepath\u003dpath+filename\n",
        "        print(\"Downloading \",filepath)\n",
        "        size \u003d ftp.size(filepath)\n",
        "        global bar\n",
        "        bar \u003d ProgressBar(widgets\u003d[\u0027Downloading: \u0027, Percentage(), \u0027 \u0027,\n",
        "                        Bar(marker\u003d\u0027#\u0027,left\u003d\u0027[\u0027,right\u003d\u0027]\u0027),\n",
        "                        \u0027 \u0027, ETA(), \u0027 \u0027, FileTransferSpeed()], maxval\u003dsize)\n",
        "        bar.start()    \n",
        "        global f\n",
        "        f \u003d open(filename, \u0027wb\u0027)  \n",
        "        #ftp.cwd(path)\n",
        "        #ftp.retrbinary(\"RETR \" + filename, open(filename, \"wb\").write)\n",
        "        ftp.retrbinary(\"RETR \" + filepath, download_file_with_progressbar)\n",
        "\n",
        "        ftp.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/Pathology/Data/WSI\n",
            "Downloading \u0027tumor_091.tif\u0027...\n",
            "Downloading  gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/training/tumor/tumor_091.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100% [################################] ETA:  00:00:00   3.5 MiB/s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading \u0027tumor_107.tif\u0027...\n",
            "Downloading  gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/training/tumor/tumor_107.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100% [################################] ETA:  00:00:00   4.6 MiB/s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading \u0027normal_042.tif\u0027...\n",
            "Downloading  gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/training/normal/normal_042.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading:  99% [############################### ] ETA:   0:00:00   1.8 MiB/s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading \u0027normal_150.tif\u0027...\n",
            "Downloading  gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/training/normal/normal_150.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100% [################################] ETA:  00:00:00   4.6 MiB/s"
          ]
        }
      ],
      "source": "%cd $DataDirWSI\ndownload_camelyon16_image(\"tumor_091.tif\")\ndownload_camelyon16_image(\"tumor_107.tif\")\ndownload_camelyon16_image(\"normal_042.tif\")\ndownload_camelyon16_image(\"normal_150.tif\")"
    },
    {
      "cell_type": "markdown",
      "source": "\u003cbr\u003e\nCheck that the files were downloaded in the correct folder ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!ls $DataDirWSI",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 1.2. Download annotation json file\nAnnotation information are adopted from \n[NCRF/jsons](https://github.com/baidu-research/NCRF/tree/master/jsons).\nCell below will download the needed files"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-04-24 16:05:26--  https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/train/Tumor_091.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51773 (51K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/jsons/Tumor_091.json’\n",
            "\n",
            "Tumor_091.json      100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]  50.56K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-24 16:05:26 (4.43 MB/s) - ‘/workspace/Pathology/Data/jsons/Tumor_091.json’ saved [51773/51773]\n",
            "\n",
            "--2021-04-24 16:05:26--  https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/valid/Tumor_107.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18059 (18K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/jsons/Tumor_107.json’\n",
            "\n",
            "Tumor_107.json      100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]  17.64K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-04-24 16:05:27 (12.6 MB/s) - ‘/workspace/Pathology/Data/jsons/Tumor_107.json’ saved [18059/18059]\n",
            "\n",
            "--2021-04-24 16:05:27--  https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/train/Normal_042.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28118 (27K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/jsons/Normal_042.json’\n",
            "\n",
            "Normal_042.json     100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]  27.46K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-04-24 16:05:27 (10.1 MB/s) - ‘/workspace/Pathology/Data/jsons/Normal_042.json’ saved [28118/28118]\n",
            "\n",
            "--2021-04-24 16:05:28--  https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/valid/Normal_150.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63525 (62K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/jsons/Normal_150.json’\n",
            "\n",
            "Normal_150.json     100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]  62.04K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-24 16:05:28 (4.13 MB/s) - ‘/workspace/Pathology/Data/jsons/Normal_150.json’ saved [63525/63525]\n",
            "\n"
          ]
        }
      ],
      "source": "jsonURL\u003d\"https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/\"\n\nwget_URL\u003djsonURL+\"train/Tumor_091.json\"\n!wget $wget_URL -P $DataDirJson --no-check-certificate\nwget_URL\u003djsonURL+\"valid/Tumor_107.json\"\n!wget $wget_URL -P $DataDirJson --no-check-certificate\nwget_URL\u003djsonURL+\"train/Normal_042.json\"\n!wget $wget_URL -P $DataDirJson --no-check-certificate\nwget_URL\u003djsonURL+\"valid/Normal_150.json\"\n!wget $wget_URL -P $DataDirJson --no-check-certificate\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 1.3. Download patch coords\nLocation information for training/validation patches are adopted from \n[NCRF/coords](https://github.com/baidu-research/NCRF/tree/master/coords).\nCell below will download the needed files"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-04-24 16:05:50--  https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/tumor_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4507595 (4.3M) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/coordsRaw/tumor_train.txt’\n",
            "\n",
            "tumor_train.txt     100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]   4.30M  5.26MB/s    in 0.8s    \n",
            "\n",
            "2021-04-24 16:05:51 (5.26 MB/s) - ‘/workspace/Pathology/Data/coordsRaw/tumor_train.txt’ saved [4507595/4507595]\n",
            "\n",
            "--2021-04-24 16:05:52--  https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/tumor_valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 443078 (433K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/coordsRaw/tumor_valid.txt’\n",
            "\n",
            "tumor_valid.txt     100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e] 432.69K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-04-24 16:05:52 (8.33 MB/s) - ‘/workspace/Pathology/Data/coordsRaw/tumor_valid.txt’ saved [443078/443078]\n",
            "\n",
            "--2021-04-24 16:05:53--  https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/normal_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4582840 (4.4M) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/coordsRaw/normal_train.txt’\n",
            "\n",
            "normal_train.txt    100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]   4.37M  8.76MB/s    in 0.5s    \n",
            "\n",
            "2021-04-24 16:05:54 (8.76 MB/s) - ‘/workspace/Pathology/Data/coordsRaw/normal_train.txt’ saved [4582840/4582840]\n",
            "\n",
            "--2021-04-24 16:05:54--  https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/normal_valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451569 (441K) [text/plain]\n",
            "Saving to: ‘/workspace/Pathology/Data/coordsRaw/normal_valid.txt’\n",
            "\n",
            "normal_valid.txt    100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e] 440.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-04-24 16:05:55 (7.98 MB/s) - ‘/workspace/Pathology/Data/coordsRaw/normal_valid.txt’ saved [451569/451569]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "coordsURL\u003d\"https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/\"\n",
        "\n",
        "wget_URL\u003dcoordsURL+\"tumor_train.txt\"\n",
        "!wget $wget_URL -P $DataDirCoordRaw --no-check-certificate\n",
        "wget_URL\u003dcoordsURL+\"tumor_valid.txt\"\n",
        "!wget $wget_URL -P $DataDirCoordRaw --no-check-certificate\n",
        "wget_URL\u003dcoordsURL+\"normal_train.txt\"\n",
        "!wget $wget_URL -P $DataDirCoordRaw --no-check-certificate\n",
        "wget_URL\u003dcoordsURL+\"normal_valid.txt\"\n",
        "!wget $wget_URL -P $DataDirCoordRaw --no-check-certificate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Let\u0027s only keep the location info for the WSIs we downloaded "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cmd\u003d\"grep Tumor_091 \"+DataDirCoordRaw+\"tumor_train.txt\"+\" \u003e \"+DataDirCoord+\"tumor_train.txt\"\n",
        "! $cmd\n",
        "cmd\u003d\"grep Tumor_107 \"+DataDirCoordRaw+\"tumor_valid.txt\"+\" \u003e \"+DataDirCoord+\"tumor_valid.txt\"\n",
        "! $cmd\n",
        "cmd\u003d\"grep Normal_042 \"+DataDirCoordRaw+\"normal_train.txt\"+\" \u003e \"+DataDirCoord+\"normal_train.txt\"\n",
        "! $cmd\n",
        "cmd\u003d\"grep Normal_150 \"+DataDirCoordRaw+\"normal_valid.txt\"+\" \u003e \"+DataDirCoord+\"normal_valid.txt\"\n",
        "! $cmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 2. Data Preparation for MMAR Training\n\nThe current sample location information, e.g. /coords/tumor_train.txt has information below:  \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/coords.png\" height\u003d\"200\"/\u003e\u003c/left\u003e\n\nIn fact, at each location, a 728x728 patch will be sampled, which will further be decomposed to a 3x3 grid of 224x224 patches. \nTherefore, we need to convert the downloaded patch coords to json that works with Clara MMAR with the following two steps:\n1. Read NCRF coords and annotation jsons, output full index/label information: `prepare_train_data.sh` is used to generate the LocLabel files needed for training and validation from /coords and /jsons listed above. It will append the labels after each filename + coordinate pairs. "
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "setting MMAR_ROOT \u003d /workspace/Pathology/MMAR_DP/\n",
            "\u001b[0m\u001b[01;34mcommands\u001b[0m/  \u001b[01;34mconfig\u001b[0m/  \u001b[01;34mcustom\u001b[0m/  \u001b[01;34mdocs\u001b[0m/  \u001b[01;34meval\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mresources\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "MMAR_ROOT\u003droot+\"/MMAR_DP/\"\n",
        "print (\"setting MMAR_ROOT \u003d\",MMAR_ROOT)\n",
        "%ls $MMAR_ROOT\n",
        "!chmod 777 $MMAR_ROOT/commands/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "../../Data//LocLabel/tumor_train.txt Total sample: 2000\n",
            "../../Data//LocLabel/normal_train.txt Total sample: 554\n",
            "../../Data//LocLabel/tumor_valid.txt Total sample: 2000\n",
            "../../Data//LocLabel/normal_valid.txt Total sample: 339\n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/prepare_train_data.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "It will identify all 9 labels at each sample location \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/loclabel.png\" height\u003d\"200\"/\u003e\u003c/left\u003e\n\nCell below will display head of each file"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!head -5 $DataDirLoc/tumor_train.txt\n!head -5 $DataDirLoc/normal_train.txt\n!head -5 $DataDirLoc/tumor_valid.txt\n!head -5 $DataDirLoc/normal_valid.txt\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "2. Then we combine the txt files to a single json which will be used by Clara MMAR using `prepare_json.sh`",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/prepare_json.sh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "This will produce a single json file /Data/datalist.json that will be used by Clara MMAR "
    },
    {
      "cell_type": "code",
      "source": "! head -30 $DataDirRoot/datalist.json",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "\u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/clara_json.png\" width\u003d\"400\"/\u003e\u003c/left\u003e\n\nAs shown above, each sample Clara accepts for training/validation has the information on WSI path, sample location, and the 9 corresponding labels. Now we have the necessary input for the training/validation pipeline: \n1. path to the folder containing all WSIs\n2. json file listing the location and label information for training patches.\n\nThe paths are set in /config/environment.json \u003cbr\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "## 3. Clara MMAR Training \n### Model Overview\nThe model is based on ResNet18 with the last fully connected layer replaced by a 1x1 convolution layer."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### WSI Reader \u003cspan style\u003d\"color:red\"\u003e(New in V4 I)\u003c/span\u003e\nWe recommend using [cuCIM](https://github.com/rapidsai/cucim/), \nan extensible toolkit designed to provide GPU accelerated I/O, \ncomputer vision \u0026 image processing primitives for N-Dimensional images with a focus on biomedical imaging, \nto load WSI images. [OpenSlide](https://openslide.org/), the popular WSI-reader, is also provided for convenience. \nUsers can choose between the two using the option in config files\u003cbr\u003e\n\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/wsireader.png\" width\u003d\"700\"/\u003e\u003c/left\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 3.1 Training\nTraining can be performed regularly, or with [Smart Cache](https://docs.nvidia.com/clara/tlt-mi/nvmidl/additional_features/smart_cache.html) mechanism.\n\nBefore we get started lets check that we have an NVIDIA GPU available in the docker by running the cell below."
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 24 16:56:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d+\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d+\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d|\n",
            "|   0  TITAN Xp COLLEC...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
            "| 23%   26C    P8     9W / 250W |     11MiB / 12196MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "#### 3.1.1 Regular Training\nThen we can start regular training (w/o smart cache mechanism). For this example, we will train for 4 epochs with /commands/train.sh. \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/train.png\" width\u003d\"300\"/\u003e\u003c/left\u003e    "
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "2021-04-24 19:47:40,690 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpyg24r742\n",
            "2021-04-24 19:47:40,691 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpyg24r742/_remote_module_non_sriptable.py\n",
            "[Plugin: cucim.kit.cuslide] Loading...\n",
            "[Plugin: cucim.kit.cuslide] Loading the dynamic library from: /opt/conda/lib/python3.8/site-packages/cucim/clara/cucim.kit.cuslide@0.19.0.so\n",
            "[Plugin: cucim.kit.cuslide] loaded successfully. Version: 0\n",
            "Initializing plugin: cucim.kit.cuslide (interfaces: [cucim::io::IImageFormat v0.1]) (impl: cucim.kit.cuslide)\n",
            "TIFFFetchDirectory: /workspace/Pathology/Data/WSI/normal_150.tif: Can not read TIFF directory count.\n",
            "TIFFReadDirectory: Failed to read directory at offset 752212430.\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Train Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Num Epochs:  4\n",
            "Use GPU:  True\n",
            "Multi GPU:  False\n",
            "Automatic Mixed Precision:  Enabled\n",
            "Determinism Training:  Enabled\n",
            "cuDNN BenchMark:  False\n",
            "CUDA Matmul Allow TF32:  True\n",
            "cuDNN Allow TF32:  True\n",
            "Model:  \u003cclass \u0027monai.networks.nets.torchvision_fc.TorchVisionFullyConvModel\u0027\u003e\n",
            "Loss:  \u003cclass \u0027torch.nn.modules.loss.BCEWithLogitsLoss\u0027\u003e\n",
            "Optimizer:  \u003cclass \u0027monai.optimizers.novograd.Novograd\u0027\u003e\n",
            "LR Scheduler:  \u003cclass \u0027torch.optim.lr_scheduler.CosineAnnealingLR\u0027\u003e\n",
            "Train Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.PatchWSIDataset\u0027\u003e\n",
            "Train DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Train Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Train Transform #2: \u003cclass \u0027monai.transforms.utility.dictionary.TorchVisiond\u0027\u003e\n",
            "Train Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToNumpyd\u0027\u003e\n",
            "Train Transform #4: \u003cclass \u0027monai.transforms.spatial.dictionary.RandFlipd\u0027\u003e\n",
            "Train Transform #5: \u003cclass \u0027monai.transforms.spatial.dictionary.RandRotate90d\u0027\u003e\n",
            "Train Transform #6: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Train Transform #7: \u003cclass \u0027monai.transforms.spatial.dictionary.RandZoomd\u0027\u003e\n",
            "Train Transform #8: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Train Transform #9: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Validate Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.PatchWSIDataset\u0027\u003e\n",
            "Validate DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Validate Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Validate Transform #2: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Validate Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Train Handler #1: \u003cclass \u0027monai.handlers.lr_schedule_handler.LrScheduleHandler\u0027\u003e\n",
            "Train Handler #2: \u003cclass \u0027monai.handlers.validation_handler.ValidationHandler\u0027\u003e\n",
            "Train Handler #3: \u003cclass \u0027monai.handlers.checkpoint_saver.CheckpointSaver\u0027\u003e\n",
            "Train Handler #4: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Train Handler #5: \u003cclass \u0027monai.handlers.tensorboard_handlers.TensorBoardStatsHandler\u0027\u003e\n",
            "Validate Handler #1: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Validate Handler #2: \u003cclass \u0027monai.handlers.tensorboard_handlers.TensorBoardStatsHandler\u0027\u003e\n",
            "Validate Handler #3: \u003cclass \u0027monai.handlers.checkpoint_saver.CheckpointSaver\u0027\u003e\n",
            "Train Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Train Post Transforms #2: \u003cclass \u0027monai.transforms.post.dictionary.AsDiscreted\u0027\u003e\n",
            "Validate Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Validate Post Transforms #2: \u003cclass \u0027monai.transforms.post.dictionary.AsDiscreted\u0027\u003e\n",
            "Validate Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "Validate Key Metric:  \u003cclass \u0027ignite.metrics.accuracy.Accuracy\u0027\u003e\n",
            "Train Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "Train Key Metric:  \u003cclass \u0027ignite.metrics.accuracy.Accuracy\u0027\u003e\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d End of Train Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "2021-04-24 19:47:43,611 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 4 epochs\n",
            "2021-04-24 19:48:03,235 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/4, Iter: 1/32 -- train_loss: 0.7248 \n",
            "2021-04-24 19:48:05,009 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/4, Iter: 2/32 -- train_loss: 0.7290 \n",
            "2021-04-24 19:48:06,683 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/4, Iter: 3/32 -- train_loss: 0.6890 \n",
            "^C\n",
            "2021-04-24 19:48:07,144 - ignite.engine.engine.SupervisedTrainer - ERROR - Engine run is terminating due to exception: \n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/train.sh "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "#### 3.1.2 Smart Cache Training\nWe can also use smart cache training, which can be especially helpful for pathology applications due to the massive amount of patches used during training. For this example, we will cache 2000 samples and train for 40 smart cache epoches, with /commands/train_smartcache.sh, which will save the output models to models_sc/ \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/train_sc.png\" width\u003d\"300\"/\u003e\u003c/left\u003e    "
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "2021-04-24 17:58:35,458 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp46voxr1_\n",
            "2021-04-24 17:58:35,458 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp46voxr1_/_remote_module_non_sriptable.py\n",
            "[Plugin: cucim.kit.cuslide] Loading...\n",
            "[Plugin: cucim.kit.cuslide] Loading the dynamic library from: /opt/conda/lib/python3.8/site-packages/cucim/clara/cucim.kit.cuslide@0.19.0.so\n",
            "[Plugin: cucim.kit.cuslide] loaded successfully. Version: 0\n",
            "Initializing plugin: cucim.kit.cuslide (interfaces: [cucim::io::IImageFormat v0.1]) (impl: cucim.kit.cuslide)\n",
            "Loading dataset: 100%|██████████████████████| 2000/2000 [01:08\u003c00:00, 29.21it/s]\n",
            "TIFFFetchDirectory: /workspace/Pathology/Data/WSI/normal_150.tif: Can not read TIFF directory count.\n",
            "TIFFReadDirectory: Failed to read directory at offset 752212430.\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Train Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Num Epochs:  40\n",
            "Use GPU:  True\n",
            "Multi GPU:  False\n",
            "Automatic Mixed Precision:  Enabled\n",
            "Determinism Training:  Enabled\n",
            "cuDNN BenchMark:  False\n",
            "CUDA Matmul Allow TF32:  True\n",
            "cuDNN Allow TF32:  True\n",
            "Model:  \u003cclass \u0027monai.networks.nets.torchvision_fc.TorchVisionFullyConvModel\u0027\u003e\n",
            "Loss:  \u003cclass \u0027torch.nn.modules.loss.BCEWithLogitsLoss\u0027\u003e\n",
            "Optimizer:  \u003cclass \u0027monai.optimizers.novograd.Novograd\u0027\u003e\n",
            "LR Scheduler:  \u003cclass \u0027torch.optim.lr_scheduler.CosineAnnealingLR\u0027\u003e\n",
            "Train Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.SmartCachePatchWSIDataset\u0027\u003e\n",
            "SmartCache is enabled for training, total epoch 40 with cache num 2000 and replace num 554.\n",
            "For total data size 2554, this is equivalent to 31.323414252153484 regular epochs, and the data coverage rate is 1.0.\n",
            "Train DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Train Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Train Transform #2: \u003cclass \u0027monai.transforms.utility.dictionary.TorchVisiond\u0027\u003e\n",
            "Train Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToNumpyd\u0027\u003e\n",
            "Train Transform #4: \u003cclass \u0027monai.transforms.spatial.dictionary.RandFlipd\u0027\u003e\n",
            "Train Transform #5: \u003cclass \u0027monai.transforms.spatial.dictionary.RandRotate90d\u0027\u003e\n",
            "Train Transform #6: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Train Transform #7: \u003cclass \u0027monai.transforms.spatial.dictionary.RandZoomd\u0027\u003e\n",
            "Train Transform #8: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Train Transform #9: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Validate Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.PatchWSIDataset\u0027\u003e\n",
            "Validate DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Validate Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Validate Transform #2: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Validate Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Train Handler #1: \u003cclass \u0027monai.handlers.smartcache_handler.SmartCacheHandler\u0027\u003e\n",
            "Train Handler #2: \u003cclass \u0027monai.handlers.lr_schedule_handler.LrScheduleHandler\u0027\u003e\n",
            "Train Handler #3: \u003cclass \u0027monai.handlers.validation_handler.ValidationHandler\u0027\u003e\n",
            "Train Handler #4: \u003cclass \u0027monai.handlers.checkpoint_saver.CheckpointSaver\u0027\u003e\n",
            "Train Handler #5: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Train Handler #6: \u003cclass \u0027monai.handlers.tensorboard_handlers.TensorBoardStatsHandler\u0027\u003e\n",
            "Validate Handler #1: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Validate Handler #2: \u003cclass \u0027monai.handlers.tensorboard_handlers.TensorBoardStatsHandler\u0027\u003e\n",
            "Validate Handler #3: \u003cclass \u0027monai.handlers.checkpoint_saver.CheckpointSaver\u0027\u003e\n",
            "Train Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Train Post Transforms #2: \u003cclass \u0027monai.transforms.post.dictionary.AsDiscreted\u0027\u003e\n",
            "Validate Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Validate Post Transforms #2: \u003cclass \u0027monai.transforms.post.dictionary.AsDiscreted\u0027\u003e\n",
            "Validate Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "Validate Key Metric:  \u003cclass \u0027ignite.metrics.accuracy.Accuracy\u0027\u003e\n",
            "Train Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "Train Key Metric:  \u003cclass \u0027ignite.metrics.accuracy.Accuracy\u0027\u003e\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d End of Train Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "2021-04-24 17:59:46,871 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 40 epochs\n",
            "2021-04-24 17:59:54,376 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 1/25 -- train_loss: 0.7295 \n",
            "2021-04-24 17:59:56,159 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 2/25 -- train_loss: 0.7255 \n",
            "2021-04-24 17:59:57,910 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 3/25 -- train_loss: 0.7021 \n",
            "2021-04-24 17:59:59,511 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 4/25 -- train_loss: 0.6560 \n",
            "2021-04-24 18:00:01,126 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 5/25 -- train_loss: 0.6340 \n",
            "2021-04-24 18:00:02,773 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 6/25 -- train_loss: 0.6001 \n",
            "2021-04-24 18:00:04,558 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 7/25 -- train_loss: 0.5373 \n",
            "2021-04-24 18:00:06,199 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 8/25 -- train_loss: 0.4875 \n",
            "2021-04-24 18:00:07,945 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 9/25 -- train_loss: 0.4603 \n",
            "2021-04-24 18:00:09,534 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 10/25 -- train_loss: 0.4286 \n",
            "2021-04-24 18:00:11,327 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 11/25 -- train_loss: 0.4424 \n",
            "2021-04-24 18:00:12,821 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 12/25 -- train_loss: 0.3746 \n",
            "2021-04-24 18:00:14,285 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 13/25 -- train_loss: 0.3755 \n",
            "2021-04-24 18:00:15,747 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 14/25 -- train_loss: 0.3939 \n",
            "2021-04-24 18:00:17,251 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 15/25 -- train_loss: 0.3015 \n",
            "2021-04-24 18:00:18,717 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 16/25 -- train_loss: 0.2951 \n",
            "2021-04-24 18:00:20,202 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 17/25 -- train_loss: 0.3054 \n",
            "2021-04-24 18:00:21,668 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 18/25 -- train_loss: 0.2847 \n",
            "2021-04-24 18:00:23,183 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 19/25 -- train_loss: 0.3042 \n",
            "2021-04-24 18:00:24,658 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 20/25 -- train_loss: 0.2504 \n",
            "2021-04-24 18:00:26,121 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 21/25 -- train_loss: 0.2994 \n",
            "2021-04-24 18:00:27,596 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 22/25 -- train_loss: 0.2274 \n",
            "2021-04-24 18:00:29,098 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 23/25 -- train_loss: 0.2348 \n",
            "2021-04-24 18:00:30,572 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 24/25 -- train_loss: 0.2303 \n",
            "2021-04-24 18:00:32,064 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/40, Iter: 25/25 -- train_loss: 0.2165 \n",
            "2021-04-24 18:00:32,065 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_acc: 0.8205555555555556\n",
            "2021-04-24 18:00:32,094 - ignite.engine.engine.SupervisedTrainer - INFO - Current learning rate: 0.000998458666866564\n",
            "2021-04-24 18:00:32,094 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Metrics -- train_acc: 0.8206 \n",
            "2021-04-24 18:00:32,095 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_acc best value: 0.8205555555555556 at epoch: 1\n",
            "2021-04-24 18:00:32,096 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:45\n",
            "2021-04-24 18:00:38,025 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/40, Iter: 1/25 -- train_loss: 0.1938 \n",
            "2021-04-24 18:00:40,170 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/40, Iter: 2/25 -- train_loss: 0.1835 \n",
            "2021-04-24 18:00:41,808 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/40, Iter: 3/25 -- train_loss: 0.1643 \n",
            "2021-04-24 18:00:43,432 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/40, Iter: 4/25 -- train_loss: 0.2248 \n",
            "2021-04-24 18:00:45,151 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/40, Iter: 5/25 -- train_loss: 0.1735 \n",
            "^C\n",
            "2021-04-24 18:11:17,154 - ignite.engine.engine.SupervisedTrainer - ERROR - Engine run is terminating due to exception: \n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/train_smartcache.sh "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 3.2 Scores and Results\nExample shown here uses the minimum amount of WSIs for simplicity and illustrating how the pipeline works. \nTherefore, the resulting model is a dummy one that is not useful. \nYou can either download and train on all the data, or use our model form NGC."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 3.3 Model Export\nModel will be exported to torch script format "
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "2021-04-24 18:14:37,136 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpmjqgjq11\n",
            "2021-04-24 18:14:37,136 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpmjqgjq11/_remote_module_non_sriptable.py\n",
            "Exported model has been tested with TorchScript, and the result looks good!\n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/export.sh "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 3.4 Validation\nTo run validation on patches, simply run cell below."
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "2021-04-24 18:15:08,854 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmplgyx9j04\n",
            "2021-04-24 18:15:08,854 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmplgyx9j04/_remote_module_non_sriptable.py\n",
            "loaded TorchScript model from path: /workspace/Pathology/MMAR_DP/commands/../models/model.ts\n",
            "[Plugin: cucim.kit.cuslide] Loading...\n",
            "[Plugin: cucim.kit.cuslide] Loading the dynamic library from: /opt/conda/lib/python3.8/site-packages/cucim/clara/cucim.kit.cuslide@0.19.0.so\n",
            "[Plugin: cucim.kit.cuslide] loaded successfully. Version: 0\n",
            "Initializing plugin: cucim.kit.cuslide (interfaces: [cucim::io::IImageFormat v0.1]) (impl: cucim.kit.cuslide)\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Validate Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Use GPU:  True\n",
            "Multi GPU:  False\n",
            "Automatic Mixed Precision:  Enabled\n",
            "Determinism Evaluation:  Disabled\n",
            "cuDNN BenchMark:  False\n",
            "CUDA Matmul Allow TF32:  True\n",
            "cuDNN Allow TF32:  True\n",
            "Model:  \u003cclass \u0027torch.jit._script.RecursiveScriptModule\u0027\u003e\n",
            "Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.PatchWSIDataset\u0027\u003e\n",
            "DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Validate Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Validate Transform #2: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Validate Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Validate Handler #1: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Validate Handler #2: \u003cclass \u0027monai.handlers.metrics_saver.MetricsSaver\u0027\u003e\n",
            "Validate Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Validate Post Transforms #2: \u003cclass \u0027monai.transforms.post.dictionary.AsDiscreted\u0027\u003e\n",
            "Validate Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "Validate Key Metric:  \u003cclass \u0027ignite.metrics.accuracy.Accuracy\u0027\u003e\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d End of Validate Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "2021-04-24 18:15:11,619 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
            "iter: 10/32\n",
            "iter: 20/32\n",
            "iter: 30/32\n",
            "2021-04-24 18:15:26,643 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_acc: 0.9664143391629688\n",
            "2021-04-24 18:15:26,643 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Metrics -- val_acc: 0.9664 \n",
            "2021-04-24 18:15:26,643 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_acc best value: 0.9664143391629688 at epoch: 1\n",
            "2021-04-24 18:15:26,643 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:00:15\n",
            "2021-04-24 18:15:26,643 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:15\n",
            "2021-04-24 18:15:26,684 - medl.apps.mmar_conf - INFO - Total Evaluation Time 15.064562797546387\n",
            "[Plugin: cucim.kit.cuslide] Unloaded.\n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/validate.sh "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### 3.5 Inference on a WSI\nOutput of the network itself is the probability map of the input patch.\n\nInference can then be performed on WSI in a sliding window manner with specified stride. \n\nA foreground mask is needed to specify the region where the inference will be performed on, given that background region which contains no tissue at all can occupy a significant portion of a WSI. \n\nOtsu thresholding in `prepare_inference_data.sh` is used to generate foreground masks that will be used to reduce computation burden during inference. The input is the test image, and output is its foreground mask."
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "tumor_107\n",
            "Current time : 18:15:54\n",
            "normal_150\n",
            "Current time : 18:15:56\n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/Pathology/MMAR_DP/commands/../custom/tissue_mask.py\", line 60, in \u003cmodule\u003e\n",
            "    main()\n",
            "  File \"/workspace/Pathology/MMAR_DP/commands/../custom/tissue_mask.py\", line 56, in main\n",
            "    run(args)\n",
            "  File \"/workspace/Pathology/MMAR_DP/commands/../custom/tissue_mask.py\", line 29, in run\n",
            "    slide \u003d openslide.OpenSlide(args.wsi_path)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/openslide/__init__.py\", line 160, in __init__\n",
            "    self._osr \u003d lowlevel.open(filename)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/openslide/lowlevel.py\", line 128, in _check_open\n",
            "    raise OpenSlideUnsupportedFormatError(\n",
            "openslide.lowlevel.OpenSlideUnsupportedFormatError: Unsupported or missing image file\n",
            "tumor_091\n",
            "Current time : 18:15:57\n",
            "normal_042\n",
            "Current time : 18:15:58\n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/prepare_inference_data.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "With the foreground map, inference can be performed on the WSI. Output of the inference pipeline is a probability map of size 1/stride of original WSI size.\nIn datalist.json, the inference on full WSIs is specified under \"testing\" \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/testing.png\" width\u003d\"300\"/\u003e\u003c/left\u003e \n\nInference will be performed by /commands/infer.sh, results will be saved to /eval"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MMAR_ROOT set to /workspace/Pathology/MMAR_DP/commands/..\n",
            "2021-04-24 18:28:03,215 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp7muy3spw\n",
            "2021-04-24 18:28:03,216 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp7muy3spw/_remote_module_non_sriptable.py\n",
            "loaded TorchScript model from path: /workspace/Pathology/MMAR_DP/commands/../models/model.ts\n",
            "[Plugin: cucim.kit.cuslide] Loading...\n",
            "[Plugin: cucim.kit.cuslide] Loading the dynamic library from: /opt/conda/lib/python3.8/site-packages/cucim/clara/cucim.kit.cuslide@0.19.0.so\n",
            "[Plugin: cucim.kit.cuslide] loaded successfully. Version: 0\n",
            "Initializing plugin: cucim.kit.cuslide (interfaces: [cucim::io::IImageFormat v0.1]) (impl: cucim.kit.cuslide)\n",
            "This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Validate Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Use GPU:  True\n",
            "Multi GPU:  False\n",
            "Automatic Mixed Precision:  Enabled\n",
            "Determinism Evaluation:  Disabled\n",
            "cuDNN BenchMark:  False\n",
            "CUDA Matmul Allow TF32:  True\n",
            "cuDNN Allow TF32:  True\n",
            "Model:  \u003cclass \u0027torch.jit._script.RecursiveScriptModule\u0027\u003e\n",
            "Dataset:  \u003cclass \u0027monai.apps.pathology.datasets.MaskedInferenceWSIDataset\u0027\u003e\n",
            "DataLoader:  \u003cclass \u0027monai.data.dataloader.DataLoader\u0027\u003e\n",
            "Validate Transform #1: \u003cclass \u0027monai.transforms.utility.dictionary.CastToTyped\u0027\u003e\n",
            "Validate Transform #2: \u003cclass \u0027monai.transforms.intensity.dictionary.ScaleIntensityRanged\u0027\u003e\n",
            "Validate Transform #3: \u003cclass \u0027monai.transforms.utility.dictionary.ToTensord\u0027\u003e\n",
            "Validate Handler #1: \u003cclass \u0027monai.handlers.stats_handler.StatsHandler\u0027\u003e\n",
            "Validate Handler #2: \u003cclass \u0027monai.apps.pathology.handlers.ProbMapProducer\u0027\u003e\n",
            "Validate Post Transforms #1: \u003cclass \u0027monai.transforms.post.dictionary.Activationsd\u0027\u003e\n",
            "Validate Inferer:  \u003cclass \u0027monai.inferers.inferer.SimpleInferer\u0027\u003e\n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d End of Validate Config Result \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "2021-04-24 18:28:06,253 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
            "image: \"tumor_091\", iter: 100/363\n",
            "image: \"tumor_091\", iter: 200/363\n",
            "image: \"tumor_091\", iter: 300/363\n",
            "2021-04-24 18:29:42,191 - ignite.engine.engine.SupervisedEvaluator - INFO - Inference of \u0027tumor_091\u0027 is done [1/1]!\n",
            "2021-04-24 18:29:42,191 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:01:35\n",
            "2021-04-24 18:29:42,191 - ignite.engine.engine.SupervisedEvaluator - INFO - Probability map is created for 1/1 images!\n",
            "2021-04-24 18:29:42,191 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:01:36\n",
            "2021-04-24 18:29:42,312 - medl.apps.mmar_conf - INFO - Total Evaluation Time 96.0598156452179\n",
            "[Plugin: cucim.kit.cuslide] Unloaded.\n"
          ]
        }
      ],
      "source": [
        "! $MMAR_ROOT/commands/infer.sh "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "## 4. Clara MMAR Performance on Full Camelyon16 Data \nFor reference, we list the performance of Clara Paholoygy Detection MMAR on full Camelyon16 data. The experiments are performed using a single 32 GB V100 GPU on a [NVIDIA DGX-2 System](https://www.nvidia.com/en-us/data-center/dgx-2/) \n\nBenchmarking with [NCRF](https://github.com/baidu-research/NCRF) (Resnet18 baseline, without CRF), which was implemented with pytorch and OpenSlide, we used the same patch locations and performed same 20 epoch experiments.  \n\nSummary for all experiments (time in hours), note that NCRF need to generate PNG files for patches, while Clara loads the patches on the fly:\n \n \n Experiment | uses pre-trained \u003cbr/\u003emodel | AMP | Library | 2D Patch \u003cbr/\u003eGeneration | Training \u003cbr/\u003e(20 epochs) | Total \u003cbr/\u003eTraining Time | Speedup | Best \u003cbr/\u003eModel | FROC on 48 \u003cbr/\u003eTest Cases | Training Speedup \u003cbr/\u003eat Best Model\n :--- | :---: | :---: | :---: | :---: | :---:| :----:| :----:| :----:| :----:| :---:\n NCRF | No | NoAmp | - | 10 | 70.5 | 80.5 | 1x | 35.5 | 0.69 | 1x\n Clara | yes | Amp | OpenSlide | N/A | 48.5 | 48.5 | 1.66x | 5.5 | 0.71 | 8x\n Clara | yes | Amp | **cuCIM** | N/A | **39.5** | **39.5** | **2x** | **4.5** | **0.72** | **10x**\n\n\u003cbr\u003e\n\n**For inference**\n \nExperiment | pre-trained | Inference | speedup  \n --- | --- |  ---:| ---:\n NCRF | - | 26.5 | 1x\n Clara | OpenSlide | 2 | 13x\n Clara | cuCIM | 2 | 13x\n\n\nInference speedup is due to 2 factors:\n1. Optimized inference pipeline by Clara \n2. Larger batch size used (80 v.s. 20)\n"
    },
    {
      "cell_type": "markdown",
      "source": "Training curve of NCRF:\u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/ncrf.png\" width\u003d\"600\"/\u003e\u003c/left\u003e \n\nTraining curve of Clara regular training:\u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/reg_train_loss.png\" width\u003d\"600\"/\u003e\u003c/left\u003e \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/reg_val_acc.png\" width\u003d\"600\"/\u003e\u003c/left\u003e \n\nTraining curve of Clara training with smart cache:\u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/sc_train_loss.png\" width\u003d\"600\"/\u003e\u003c/left\u003e \u003cbr\u003e\n\u003cleft\u003e\u003cimg src\u003d\"screenShots/sc_val_acc.png\" width\u003d\"600\"/\u003e\u003c/left\u003e ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "\n"
    },
    {
      "cell_type": "markdown",
      "source": "# Exercise \n### 1. Train using open slide \nYou can compare performance against openslide.\nFor this you would to install openslide packages by running cell below \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# Install openslide packages  \n!apt-get -y install openslide-tools\n!apt-get -y install python-openslide\n!python3 -m pip install --upgrade pip\n!pip install openslide-python",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": " \nYou can change the data loader to use open slide, \nfor this you would need to change the config_train.json or the \n\nyou simply need to change \n```\n        \"image_reader_name\": \"cuclaraimage\"\n``` \nto \n```\n        \"image_reader_name\": \"openslide\"\n``` \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}