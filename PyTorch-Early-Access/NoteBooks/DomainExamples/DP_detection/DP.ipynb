{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Note book for Digital Pathology usecase \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n# Description\n\nA pre-trained model for automated detection of metastases in whole-slide histopathology images. \nThe prediction map is generated in a sliding-window manner by classifying local 224x224x3 RGB patches as either tumor or normal.\n\n# Disclamer \nThis note book will use a single file to train. \nThis is **ONLY** intended to show the user how to easily get started. \nFor the best model please download the final model from NGC. \n\n## Prerequisites\n- Before running any code, please install \"openslide-python\" and OpenSlide libraries.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### (Temporarily till GA)\nWe noticed some torch version issues that would be fixed in GA release. \nFor you cell below would fix the issue ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!pip install --no-deps torchvision\u003d\u003d0.8.0",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### (optional) Install openslide \nIf you would like to compare performance against openslide, \nyou would need to install openslide packages. \nLater on you can change the data loader to use openslide ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!apt-get -y install openslide-tools\n!apt-get -y install python-openslide\n!python3 -m pip install --upgrade pip\n!pip install openslide-python\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 1. Download Data\nAll the data used to train, validate, and test this model is from \n[Camelyon-16 Challenge](https://camelyon16.grand-challenge.org/).\nFirst lets setup directories for the data ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import os\nDataDirRoot\u003d\"/claraDevDay/Data/DP_CAMELYON16/\"\n\nDataDirJson\u003dDataDirRoot+\"jsons/train/\"\nDataDirCoord\u003dDataDirRoot+\"coords/\"\nos.makedirs(DataDirCoord, exist_ok\u003dTrue)\nos.makedirs(DataDirJson, exist_ok\u003dTrue)\nos.makedirs(DataDirRoot+\"tif/\", exist_ok\u003dTrue)\nos.makedirs(DataDirRoot+\"LocLabel/\", exist_ok\u003dTrue)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1.1 Download tiff manually \nYou can download all the images for \"CAMELYON16 data set\" from various sources listed \n[here](https://camelyon17.grand-challenge.org/Data/).\nFor simplicity you only need the smallest file tumor_091.tif (500Mb) \u003cbr\u003e\n**Please note: This download would take 15+ minutes**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "%cd $DataDirRoot/tif",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import ftplib\nimport os\n\ndef download_camelyon16_image(filename):\n    filename \u003d filename.lower()\n    if os.path.exists(filename):\n        print(f\"The image [{filename}] already exist locally.\")\n    else:\n        print(f\"Downloading \u0027{filename}\u0027...\")\n        prefix \u003d filename.split(\"_\")[0].lower()\n        if prefix \u003d\u003d \"test\":\n            folder_name \u003d \"testing/images\"\n        elif prefix in [\"normal\", \"tumor\"]:\n            folder_name \u003d f\"training/{prefix}\"\n        else:\n            raise ValueError(\n                f\"\u0027{filename}\u0027 not found on the server.\"\n                \" File name should be like \u0027test_001.tif\u0027, \u0027tumor_001.tif\u0027, or \u0027normal_001.tif\u0027\"\n            )\n        path \u003d f\"gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/{folder_name}/\"\n        ftp \u003d ftplib.FTP(\"parrot.genomics.cn\")\n        ftp.login(\"anonymous\", \"\")\n        ftp.cwd(path)\n        ftp.retrbinary(\"RETR \" + filename, open(filename, \"wb\").write)\n        ftp.quit()\n\ndownload_camelyon16_image(\"tumor_091.tif\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nCheck that file was downloaded in tif folder ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!ls $DataDirRoot/tif    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1.2. Download Json files\nLocation information for training/validation patches are adopted from \n[NCRF/coords](https://github.com/baidu-research/NCRF/tree/master/coords).\nCell below will download the needed files",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "DataDirJson\u003dDataDirRoot+\"jsons/train/\"\nblobURL\u003d\"https://raw.githubusercontent.com/baidu-research/NCRF/master/jsons/train/\"\n\nFileName\u003d\"Tumor_091.json\"\nwget_URL\u003dblobURL+FileName\n!wget $wget_URL -P $DataDirJson",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1.3. Download coords\nAnotation information are adopted from \n[NCRF/jsons](https://github.com/baidu-research/NCRF/tree/master/jsons).\nCell below will download the needed files",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "coordsURL\u003d\"https://raw.githubusercontent.com/baidu-research/NCRF/master/coords/\"\nFileName\u003d\"tumor_train.txt\"\nwget_URL\u003dcoordsURL+FileName\n!wget $wget_URL -P $DataDirRoot",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "let\u0027s only keep locations for tumors we downloaded ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "cmd\u003d\"grep Tumor_091 \"+DataDirRoot+FileName+\" \u003e \"+DataDirCoord+FileName\n! $cmd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Lets Get Started\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "MMAR_ROOT\u003d\"/claraDevDay/DomainExamples/DP_detection/\"\nprint (\"setting MMAR_ROOT\u003d\",MMAR_ROOT)\n%ls $MMAR_ROOT\n!chmod 777 $MMAR_ROOT/commands/*",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 2. Data Preparation\n\n#### Input and output formats\n\nInput for the training pipeline includes: \n1. folder containing all WSIs\n2. txt files listing the location and label information for training patches.\n\nOutput of the network itself is the probability of a 224x224x3 patch.\n\n- For training / validation: `prepare_train_data.sh` is used to generate the LocLabel files needed for training and validation from /coords and /jsons listed above. It will append the labels after each filename + coordinate pairs. Together with training images, they will be passed to training/validation pipeline.\n- For inference: `prepare_inference_data.sh` is used to generate foreground masks that will be used to reduce computation burden during inference. The input is the test images, and output is the foreground masks.\n- For FROC: refer to \"Annotation\" section of [Camelyon challenge](https://camelyon17.grand-challenge.org/Data/) to prepare ground truth images, which are needed for FROC computation.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/prepare_train_data.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 3. Training \n### Model Overview\nThe model is based on ResNet18 with the option of replacing last fully connected layer by a 1x1 convolution layer.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1 Normal Training\nLets start training with basic configuration ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train.sh ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.2 Training using smart cache\nNow lets take advantage of smart cache data pipeline ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train_smartcache.sh ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Scores and Results\nExample shown here uses single tumor image for simplisity. \nTherefore, the model is a dummy model that is not useful. \nYou can either download all the data and retrain or use our model form NGC.\n\nOur trained model on NGC achieve the ~0.92 accuracy on validation patches, \nand FROC of ~0.72 on the 48 Camelyon testing data that have ground truth annotations available.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 4. Running Validation ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/validate.sh \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Inference on a WSI\n\nInference is performed on WSI in a sliding window manner with specified stride. \nA foreground mask is needed to specify the region where the inference will be performed on, \ngiven that background region which contains no tissue at all can occupy a significant portion of a WSI. \nOutput of the inference pipeline is a probability map of size 1/stride of original WSI size.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Running Inference  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/infer.sh \n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}