{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# AI Assisted Annotation \n\nManual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAASpeedup.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\nAIAA is based on a server client model as shown below \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAClientServer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "By the end of this notebook you will be able to:\n",
        "- Start AIAA server \n",
        "- Load a deep grow model\n",
        "- Annotate using deep grow \n",
        "- Load your model and use it for annotations  \n",
        "- Stop AIAA server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Prerequisites\n",
        "- Nvidia GPU with 8Gb of memory   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Resources\n",
        "It might be helpful to watch the GTC Digital 2020 talk on Clara Train SDK \n",
        "- [S22563](https://developer.nvidia.com/gtc/2020/video/S22563)\n",
        "Clara train Getting started: cover basics, BYOC, AIAA, AutoML \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## Lets get started\nBefore we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# following command should show all gpus available \n!nvidia-smi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n## 1- Start AIAA server\nThe cell below will start the AIAA server\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "AIAA_ROOT\u003d\"/claraDevDay/AIAA/workspace/\"\nAIAA_PORT\u003d\"5000\"\n!mkdir -p $AIAA_ROOT\n!chmod 777 $AIAA_ROOT\nprint (\"AIAA_ROOT is set to \",AIAA_ROOT)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# To run from a terminal you should just run\n# start_aas.sh --workspace \u003cworkspace\u003e \u0026  \nimport subprocess\na \u003d subprocess.Popen([\"start_aiaa.sh\",\"--workspace\",AIAA_ROOT])\n!sleep 10 #AIAA need a bit of time to start "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "Let us now check that the server has started by:\n- Main url [http://localhost:5000/](http://clarasa-station:5000/) \u003cbr\u003e\n- APIS to list, upload, delete models [http://localhost:5000/docs/](http://clarasa-station:5000/docs/)\n- Check logs [http://localhost:5000/logs](http://clarasa-station:5000/logs)\n- List available models [http://localhost:5000/v1/models/](http://clarasa-station:5000/v1/models) \n- Dashboard [http://localhost:5000/dashboard/](http://clarasa-station:5000/dashboard) "
    },
    {
      "cell_type": "markdown",
      "source": "You can also use web APIs as curl command to do \nThe cell below will get the last 15 lines of the logs.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      },
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/logs/?lines\u003d15\"\n!curl -X GET $http_str -H \"accept: application/json\" "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "\n##  2- Load models in AIAA Server. \nFor this notebook we can download models from [NGC](). Models on NGC are either:\n- Annotation Models \u003cbr\u003e\n[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAAnnotation.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n- Segmentation Models\n- DeepGrow MMAR \nThis is an interactive model to get you started with annotation. CNN takes in single channel (image) + use single click \nfor foreground or background location then produces the segmentation. it is based on [Interactive segmentation of medical images through\nfully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAADeepGrow.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "#### 2.1 Using NGC CLI to download model from NGC (Will NOT work for EA) \nYou can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \nYou can also use `ngc registry model list nvidia/med/clara_*` to get a list of models."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!ngc registry model list nvidia/clara_*\n",
        "!ngc registry model list nvidia/med/clara_*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "The cell below will download the the deep grow model from NGC\n***Will Not work for EA***"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# model name from NGC is clara_train_deepgrow_aiaa_inference_only\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_deepgrow\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}\u0027\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "The following cell will download the spleen model and load it into the AIAA server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_ct_seg_spleen_no_amp\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_ct_seg_spleen_no_amp\",\"version\":\"1\"}\u0027"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "#### 2.2 Manually Download model from NGC \nIf you have a private registry or have early access (EA) to nvidia\u0027s developer program, \nyou can manually downloaded the MMAR form NGC by clicking the ... button as shown below\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/DownloadFromNGC.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n**You should download zip file to /claraDevDay/AIAA/DownloadsFromNGC/**\n "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "Zip file would have the MMAR structure. \nCell below would unzip the mmar then upload it to AIAA server "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "downloadedFile\u003d\"Deepgrow2DV4EA.zip\"\n\ndownloadDir\u003dAIAA_ROOT+\"../DownloadsFromNGC/\"\nmodelName\u003ddownloadedFile[:-4]\n%cd $downloadDir\n!unzip $downloadedFile -d $modelName",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/\"+modelName\nconf_str\u003d\"config\u003d@\"+downloadDir+modelName+\"/config/config_aiaa.json;type\u003dapplication/json\"\ndataArg\u003d\"data\u003d@\"+downloadDir+modelName+\"/models/model.ts\"\ncmd\u003d\u0027curl -X PUT \"\u0027+http_str +\u0027\" -F \"\u0027+conf_str +\u0027\" -F \"\u0027+dataArg +\u0027\"\u0027\nprint(cmd)\n!$cmd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "#### 2.3 Check for models loaded into AIAA\nLet us check the server and check that the model is uploaded. after running the cell below you should see the deep grow model name returned with the description "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n!curl -X GET $http_str -H \"accept: application/json\""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3- AIAA Clients \n\nAIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n). \nNVIDIA has already implemented these APIs for a number of open source viewers as:\n"
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1. [3D Slicer](https://www.slicer.org/)\n\nIn order to use slicer you should: \n1. Install and setup slicer 3d following steps [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n    1. Download and install recent 3D Slicer Preview Release (4.11.x) from [here](http://download.slicer.org/).\n    For Early access please use slicer 4.13 (unstable release) this is needed to enable 3d geepgrow models. \n    2. Start 3D Slicer and open the Extension manager\n    3. Install NvidiaAIAssistedAnnotation extension (in Segmentation category), wait for the installation to complete, and click Restart\n2. Install by searching for nvidia in the plugin manager\n3. Configure plugin. Add the AIAA server location and make sure the session is enabled\n   \u003cbr\u003e\u003cimg src\u003d\"screenShots/SlicerConfig.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\n4. You should load a volume and start trying the spleen and deep grow model as shown below\n     \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/Slicer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.2. [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK))\nMITK is another viewer that you can use with AIAA. \nYou can download and install it [here](http://mitk.org/wiki/Downloads). \nPlease make sure you install the release with nvidia AIAA.\u003cbr\u003e\n_Note_: Deep grow is not enabled yet in MITK \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.3. [OHIF](https://docs.ohif.org/)\nWe have integrated AIAA with OHIF as a plugin, This has been adapted in to XNAT. \nPlugin code can be found as a branch of OHIF github [here](https://github.com/SachidanandAlle/Viewers) \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4- Delete Models from AIAA server  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# if you need to change the model name \n#modelName\u003d\"Deepgrow2DV4EA\" \nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\n!curl -X DELETE $http_str\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 5- Stop AIAA server  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!stop_aiaa.sh"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}