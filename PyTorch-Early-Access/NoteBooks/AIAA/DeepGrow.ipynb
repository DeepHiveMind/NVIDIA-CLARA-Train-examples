{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Train DeepGrow for AIAA\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The most important data points to enhance your model are the patients where the model performs badly. \nThat means the AIAA segmentation model would fail. \nThe fail back here is to ask radiologist to annotate/ fix errors with manual tools. \nThis is very time consuming and frustrating. \nInstead we can train a deep grow in 2D or 3D to guid your model to the area where it should segment. \nThis requires us to train a different model which is deep grow. \nHowever, the good news is this uses the same data with the same format you already have.\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAADeepGrow.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In this notebook, we will walk you through training deep grow models to be used with AIAA. \n\nThis notebook will work through the following steps:\u003cbr\u003e\n1. Train a 2D deep grow model then deploying it on AIAA server.\n2. Train a 3D deep grow model then deploying it on AIAA server. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Prerequisites\n- Familiarity with Clara train and MMAR \n- Ran step 9 in [Download Decathlon DataSet Notebook](../Data/DownloadDecathlonDataSet.ipynb) to download the spleen dataset.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## DataSet \nThe spleen segmentation task in this notebook performs volumetric (3D) segmentation \nof the spleen from CT images. The dataset used is Task09_Spleen.tar from \nthe [Medical Segmentation Decathlon](http://medicaldecathlon.com/). \nPrior to running this notebook the data should be downloaded following \nthe step 9 in [Download Decathlon DataSet Notebook](../Data/DownloadDecathlonDataSet.ipynb).\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Lets get started\nBefore we get started lets check that we have an NVIDIA GPU available in the docker by running the cell below. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# following command should show all gpus available \n!nvidia-smi",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# Run some imports and functions used in the notebook\n\n# Import some of the libraries that we will use throughout this notebook.\n\n# setting up MMAR root path\nMMAR_ROOT\u003d\"/claraDevDay/AIAA/deepgrow_2D/\"\nAIAA_PORT\u003d\"5000\"\nprint (\"MMAR_ROOT is set to \",MMAR_ROOT)\n!ls $MMAR_ROOT\n!chmod 777 $MMAR_ROOT/commands/*\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom IPython.display import Image",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 1. Train Deep grow 2D  \n \n### 1.1 Pre-processing the dataset\nDeep grow needs to generate foreground and background user clicks \nas well as removing slices without any labels. \nFor this we need to run a pre-processing script   \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "tmpDataDir\u003d\"/claraDevDay/Data/tmp4Deepgrow_2DDataPrep/\"\ndataset_root\u003d\"\"\ndataset_json\u003d\"\"\n# uncomment lines below if you are running the End2End notebook workflow\n#dataset_root\u003d\"/claraDevDay/Data/NSCLC_5/nii/\"\n#dataset_json\u003ddataset_root+\"dataSet.json\"\n\n! $MMAR_ROOT/commands/prepare_dataset.sh $tmpDataDir $dataset_root $dataset_json",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now lets check on the generated numpys",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "!ls $tmpDataDir\n!ls $tmpDataDir/images\n!ls $tmpDataDir/labels",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "\n### 1.2 Train deep grow 2D\nThe pre-processing step prepares the data and also generate the `dataset.json` file needed for training \nNow we need to adjust the `enviroment.json` then run the `train.sh`  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train.sh 2",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 1.3 Check on results be running validation\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/validate.sh\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "lets see the results of our model on the validation set.\nfirst we will make list of images then display them",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "evalImageDir\u003dMMAR_ROOT+\u0027eval/segs/\u0027\n!ls $evalImageDir\nonlyfiles \u003d [f for f in listdir(evalImageDir) if isfile(join(evalImageDir, f))]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now lets see the results ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "for f in onlyfiles:\n    display(Image(filename\u003devalImageDir+f) )",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### 1.4 Load model into AIAA \n####  1.4.1 Export the model\nTraining with this small set we can obtain a dice of 0.9. This is a great start.\nNow we need to convert the model into AIAA",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/export.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 1.4.2 Load model into AIAA ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"MySpleenDeepgrow_2D\"\nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\nconfig_str\u003d\u0027 -F config\u003d@\"\u0027+MMAR_ROOT+\u0027/config/config_aiaa.json;type\u003dapplication/json\"\u0027\nmodel_str\u003d\u0027 -F data\u003d@\"\u0027+MMAR_ROOT+\u0027/models/model.ts\"\u0027\ncmd\u003d\"curl -X PUT \"+http_str+config_str+model_str\nprint (\"running cmd \u003d \"+cmd)\n! $cmd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "No lets check that the model is loaded correctly into AIAA by checking the available models on the AIAA\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n!curl -X GET $http_str -H \"accept: application/json\"",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n#### 1.5 Test with AIAA client  \nYou should now be able to test the mode using one of the AIAA Clients as shown in [AIAA Clients](AIAA.ipynb#AIAA-Clients)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 2. Train Deep grow 3D\nWe will repeat the above steps but only changing the root mmar to point to the 3d deep grow mmar ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "MMAR_ROOT\u003d\"/claraDevDay/AIAA/deepgrow_3D/\"\nprint (\"MMAR_ROOT is set to \",MMAR_ROOT)\n!ls $MMAR_ROOT\n!chmod 777 $MMAR_ROOT/commands/*\n ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.1 Prepare the data ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "tmpDataDir\u003d\"/claraDevDay/Data/tmp4Deepgrow_3DDataPrep/\"\ndataset_root\u003d\"\"\ndataset_json\u003d\"\"\n# uncomment lines below if you are running the End2End notebook workflow\n#dataset_root\u003d\"/claraDevDay/Data/NSCLC_5/nii/\"\n#dataset_json\u003ddataset_root+\"dataSet.json\"\n\n! $MMAR_ROOT/commands/prepare_dataset.sh $tmpDataDir $dataset_root $dataset_json",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nNow lets check on the produced numpy files",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!ls $tmpDataDir\n!ls $tmpDataDir/images\n!ls $tmpDataDir/labels",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.2 Train deep grow 3D",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train.sh 2",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.3 Check on results be running validation\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/validate.sh\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "lets see the results of our model on the validation set.\nfirst we will make list of images then display them",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "evalImageDir\u003dMMAR_ROOT+\u0027eval/segs/\u0027\n!ls $evalImageDir",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can use any 3d viewer as itksnap to visualize these volume.\n  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.4 Load model into AIAA \n####  2.4.1 Export the model\nTraining with this small set we can obtain a dice of ___. This is a great start.\nNow we need to convert the model into AIAA",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/export.sh",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.4.2 Load model into AIAA ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"MySpleenDeepgrow_3D\"\nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\nconfig_str\u003d\u0027 -F config\u003d@\"\u0027+MMAR_ROOT+\u0027/config/config_aiaa.json;type\u003dapplication/json\"\u0027\nmodel_str\u003d\u0027 -F data\u003d@\"\u0027+MMAR_ROOT+\u0027/models/model.ts\"\u0027\ncmd\u003d\"curl -X PUT \"+http_str+config_str+model_str\nprint (\"running cmd \u003d \"+cmd)\n! $cmd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "No lets check that the model is loaded correctly into AIAA by checking the available models on the AIAA",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n!curl -X GET $http_str -H \"accept: application/json\"\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.5 Test with AIAA client  \nYou should now be able to test the mode using one of the AIAA Clients as shown in [AIAA Clients](AIAA.ipynb#AIAA-Clients)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 3. Creating a pipeline from 2D and 3D deep grow models\nA new feature was added which allowed to create a pipeline that triggers multiple models. \nWe have created a pipeline that would trigger 3D deepgrow model to get an inital segmentation, \nthen use the center at each slice to trigger multiple 2D deep grow. \n\nCell below adds the pipeline to the AIAA server  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "modelName\u003d\"MySpleenDeepgrow_Pipeline\"\nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\nconfig_str\u003d\u0027 -F config\u003d@\"\u0027+MMAR_ROOT+\u0027/config/deepgrow_pipeline.json;type\u003dapplication/json\"\u0027\ncmd\u003d\"curl -X PUT \"+http_str+config_str\nprint (\"running cmd \u003d \"+cmd)\n! $cmd\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "In your AIAA client (Slicer or OHIF) you can refresh the models to see the pipeline.\nSine pipeline can contain any models, pipelines would appear in the segmentation and deepgrow section\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}