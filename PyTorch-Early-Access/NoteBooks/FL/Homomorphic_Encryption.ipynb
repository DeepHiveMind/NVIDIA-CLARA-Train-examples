{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Running FL with secure aggregation using homomorphic encryption\n",
    "\n",
    "This notebook will walk you through how to setup FL with homomorphic encryption (HE). \n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this notebook, please make yourself familiar with other FL notebooks in this repo.\n",
    "\n",
    "- (Optional) Look at the introduction Notebook for [Federated Learning with Clara Train SDK](FederatedLearning.ipynb).\n",
    "- (Optional) Look at [Client Notebook](Client.ipynb).\n",
    "- (Optional) Look at [Admin Notebook](Admin.ipynb).\n",
    "- Run [Provisioning Notebook](Provisioning.ipynb) and started the server.\n",
    "\n",
    "Make sure the project.yml used for provision contains these HE related settings:\n",
    "\n",
    "    # homomorphic encryption\n",
    "    he:\n",
    "      lib: tenseal\n",
    "      config:\n",
    "        poly_modulus_degree: 8192\n",
    "        coeff_mod_bit_sizes: [60, 40, 40]\n",
    "        scale_bits: 40\n",
    "        scheme: CKKS\n",
    "        \n",
    "*Note:* These settings are recommended and should work for most tasks but could be further optimized depending on your specific model architecture and machine learning task. See this [tutorial on the CKKS scheme](https://github.com/OpenMined/TenSEAL/blob/master/tutorials/Tutorial%202%20-%20Working%20with%20Approximate%20Numbers.ipynb) and [benchmarking](https://github.com/OpenMined/TenSEAL/blob/master/tutorials/Tutorial%203%20-%20Benchmarks.ipynb) for more information of different settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "##### Option 1 \n",
    "This notebook uses a sample dataset (ie. a single image volume of the spleen dataset) provided in the package to train a small neural network for a few epochs. \n",
    "This single file is duplicated 32 times for the training set and 9 times for the validation set to mimic the full spleen dataset. \n",
    "\n",
    "##### Option 2  \n",
    "You could do minor changes as recommended in the excersise section to train on the spleen segmentation task. The dataset used is Task09_Spleen.tar from \n",
    "the [Medical Segmentation Decathlon](http://medicaldecathlon.com/). \n",
    "Prior to running this notebook the data should be downloaded following \n",
    "the steps in [Data Download Notebook](../../Data_Download.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer  \n",
    "We will be training a small networks so that both clients can fit the model on 1 gpu. \n",
    "Training will run for a couple of epochs, in order to show the concepts, we are not targeting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get started\n",
    "In order to learn how FL works with homomorphic encryption (HE) in Clara Train SDK we will first give some background on what homomorphic encryption is and how the MMAR configurations need to be modifyed to enable it.\n",
    "<br><img src=\"screenShots/homomorphic_encryption.png\" alt=\"Drawing\" style=\"height: 450px;\"/><br> \n",
    "\n",
    "## *TODO: Explain new HE components*\n",
    "- Encryptor (all layers, partial, regex)\n",
    "- Just in time HE aggregator\n",
    "- Decryptor\n",
    "- HE ShareableGenerator\n",
    "- HE Persistor\n",
    "- Cross-site validation with HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run FL experiment with HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Start server, and clients (if they are not already running)\n",
    "In the server terminal run:\n",
    "```\n",
    "cd /claraDevDay/FL/project1/server/startup\n",
    "./start.sh\n",
    "```  \n",
    "In the client1 terminal run:\n",
    "```\n",
    "cd /claraDevDay/FL/project1/client1/startup\n",
    "./start.sh\n",
    "```  \n",
    "In the client2 terminal run:\n",
    "```\n",
    "cd /claraDevDay/FL/project1/client2/startup\n",
    "./start.sh\n",
    "```  \n",
    "In the Admin terminal run:\n",
    "```\n",
    "cd /claraDevDay/FL/project1/admin/startup\n",
    "./fl_admin.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Starting Admin Shell\n",
    "In the admin terminal, if you haven't already started the admin console you should to admin folder in side your project and run\n",
    "```\n",
    "cd /claraDevDay/FL/project1/admin/startup\n",
    "./fl_admin.sh\n",
    "``` \n",
    "you should see\n",
    "```\n",
    "Admin Server: localhost on port 5000\n",
    "User Name: `\n",
    "```\n",
    "type `admin@admin.com` \n",
    "\n",
    "Admin Server: localhost on port 8003\n",
    "User Name: admin@admin.com\n",
    "\n",
    "Type ? to list commands; type \"? cmdName\" to show usage of a command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Check server/client status\n",
    "type \n",
    "```\n",
    "> check_status server\n",
    "```\n",
    "to see \n",
    "```\n",
    "FL run number has not been set.\n",
    "FL server status: training not started\n",
    "Registered clients: 2 \n",
    "-------------------------------------------------------------------------------------------------\n",
    "| CLIENT NAME | TOKEN                                | LAST ACCEPTED ROUND | CONTRIBUTION COUNT |\n",
    "-------------------------------------------------------------------------------------------------\n",
    "| client1     | f735c245-ce35-4a08-89e0-0292bb053a9c |                     | 0                  |\n",
    "| client2     | e36db52e-2624-4989-855a-28fa195f58e9 |                     | 0                  |\n",
    "-------------------------------------------------------------------------------------------------\n",
    "```\n",
    "To check on clients type \n",
    "```\n",
    "> check_status client\n",
    "```\n",
    "to see \n",
    "```\n",
    "instance:client1 : client name: client1 token: 3c3d2276-c3bf-40c1-bc02-9be84d7c339f     status: training not started\n",
    "instance:client2 : client name: client2 token: 92806548-5515-4977-894e-612900ff8b1b     status: training not started\n",
    "```\n",
    "To check on folder structure \n",
    "\n",
    "```\n",
    "> info\n",
    "```\n",
    "To see\n",
    "```\n",
    "Local Upload Source: /claraDevDay/FL/project1/admin/startup/../transfer\n",
    "Local Download Destination: /claraDevDay/FL/project1/admin/startup/../transfer\n",
    "Server Upload Destination: /claraDevDay/FL/project1/server/startup/../transfer\n",
    "Server Download Source: /claraDevDay/FL/project1/server/startup/../transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Upload and deploy the MMAR configurations for HE and set FL run number\n",
    "First set a run number (Choose a different one if you don't want to overwrite previous results)\n",
    "```\n",
    "> set_run_number 1\n",
    "```\n",
    "\n",
    "Then, upload the HE MMAR and deploy to server and clients\n",
    "```\n",
    "> upload_folder ../../../adminMMAR_HE\n",
    "> deploy adminMMAR_HE server\n",
    "> deploy adminMMAR_HE client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Start Training\n",
    "Now you can start training by:\n",
    "1. `> start server`\n",
    "2. `> start client`\n",
    "\n",
    "You can check on the status of the training using:\n",
    "1. `> check_status client` or `> check_status server`  to see \n",
    "```\n",
    "> check_status server\n",
    "FL run number:1\n",
    "FL server status: training started\n",
    "run number:1    start round:0   max round:2     current round:0\n",
    "min_num_clients:2       max_num_clients:100\n",
    "Registered clients: 2 \n",
    "Total number of clients submitted models for current round: 0\n",
    "-------------------------------------------------------------------------------------------------\n",
    "| CLIENT NAME | TOKEN                                | LAST ACCEPTED ROUND | CONTRIBUTION COUNT |\n",
    "-------------------------------------------------------------------------------------------------\n",
    "| client1     | f735c245-ce35-4a08-89e0-0292bb053a9c |                     | 0                  |\n",
    "| client2     | e36db52e-2624-4989-855a-28fa195f58e9 |                     | 0                  |\n",
    "-------------------------------------------------------------------------------------------------\n",
    "```\n",
    "2. get logs from server or clients using `cat server log.txt` or `cat client1 log.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Stop Training (if needed ) \n",
    "You could send signals to stop the training if you need to using:\n",
    "- `abort client`\n",
    "- `abort server`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Cross site validate\n",
    "Once training is completed, you would like to get the validation matrices. \n",
    "This is another area where Clara FL shines. \n",
    "Since the true power of FL is to get teh off diagonal values, which show that the model generalizes across sites. \n",
    "Before you needed to move either hte data or the selected model to each site and run validataion. \n",
    "Now with cross site validation feature it is done automatically for you.\n",
    "All you need to do is have the file `config_cross_site_validataion.json` as part of your MMAR, and have set the flag \n",
    "`\"cross_site_validate\": true` in the client section of the config_fed_client.json. \n",
    "These settings is already set up in this example so all if left is to\n",
    "\n",
    "Run `validate all` to pull the result back to the server, you could also run `validate source_site target_site`\n",
    "\n",
    "You should see something like \n",
    "```\n",
    "validate all\n",
    "{'client1': {'client2': {'validation': {'mean_dice': 0.0637669786810875}}, 'client1': {'validation': {'mean_dice': 0.07123523205518723}}, 'server': {'validation': {'mean_dice': 0.07032141834497452}}}, 'client2': {'client2': {'validation': {'mean_dice': 0.06376668065786362}}, 'client1': {'validation': {'mean_dice': 0.07123514264822006}}, 'server': {'validation': {'mean_dice': 0.07032135874032974}}}}\n",
    "Done [11570 usecs] 2020-09-03 18:49:41.485214\n",
    "``` \n",
    "parsing this json and putting it in a table would look like \n",
    "Metric = validation mean_dice \n",
    "\n",
    " _ | Client 1 | Client 2 | Server  \n",
    " :--- | :--- | :---: | --- \n",
    "Client 1 | 0.07123523205518723 | 0.0637669786810875 | 0.07032141834497452\n",
    "Client 2 | 0.07123514264822006 | 0.06376668065786362| 0.07032135874032974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
