{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# AI Assisted Annotation \n\nManual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n\u003cbr\u003e![side_bar](screenShots/AIAASpeedup.png)\n\nAIAA is based on a server client model as shown below \n\u003cbr\u003e![side_bar](screenShots/AIAAClientServer.png)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "By the end of this notebook you will be able to:\n",
        "- Start AIAA server \n",
        "- Load a deep grow model\n",
        "- Annotate using deep grow \n",
        "- Load your model and use it for annotations  \n",
        "- Stop AIAA server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Prerequisites\n",
        "- Nvidia GPU with 8Gb of memory   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Resources\n",
        "It might be helpful to watch the GTC Digital 2020 talk on Clara Train SDK \n",
        "- [S22563](https://developer.nvidia.com/gtc/2020/video/S22563)\n",
        "Clara train Getting started: cover basics, BYOC, AIAA, AutoML \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Lets get started\n",
        "Before we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# following command should show all gpus available \n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "\n",
        "### Start AIAA server\n",
        "The cell below will start the AIAA server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# setting up MMAR root path\n",
        "MMAR_ROOT\u003d\"/claraDevDay/MMARs/GettingStarted/\"\n",
        "print (\"setting MMAR_ROOT\u003d\",MMAR_ROOT)\n",
        "AIAA_ROOT\u003d\"/claraDevDay/tmp/AIAA/\"\n",
        "print (\"AIAA_ROOT is set to \",AIAA_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# To run nfrom a terminal you should just run\n",
        "# start_aas.sh --workspace \u003cworkspace\u003e \u0026  \n",
        "import subprocess\n",
        "a \u003d subprocess.Popen([\"start_aas.sh\",\"--workspace\",AIAA_ROOT])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Let us now check that the server has started by going to the url [http://localhost:5000/](http://clarasa-station:5000/) \u003cbr\u003e\n",
        "You can also check the logs at [http://localhost:5000/logs](http://clarasa-station:5000/logs) \n",
        "We could also try running `!curl -X GET \"http://127.0.0.1/logs/\" -H \"accept: application/json\"` in the terminal. \n",
        "\n",
        "The cell below will get the last 15 lines of the logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      },
      "outputs": [],
      "source": [
        "!curl -X GET \"http://127.0.0.1/logs/?lines\u003d15\" -H \"accept: application/json\" \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Load models in AIAA Server. \n",
        "For this notebook we can download models from [NGC](). Models on NGC are either:\n",
        "- Annotation Models \u003cbr\u003e\n",
        "[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n",
        "\u003cbr\u003e![side_bar](screenShots/AIAAAnnotation.png)\n",
        "- Segmentation Models\n",
        "- DeepGrow MMAR \n",
        "This is an interactive model to get you started with annotation. CNN takes in single channel (image) + use single click \n",
        "for foreground or background location then produces the segmentation. it is based on [Interactive segmentation of medical images through\n",
        "fully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n",
        "\u003cbr\u003e![side_bar](screenShots/AIAADeepGrow.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "You can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \n",
        "You can also use `ngc registry model list nvidia/med/clara_*` to get a list of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!ngc registry model list nvidia/clara_*\n",
        "!ngc registry model list nvidia/med/clara_*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "The cell below will download the the deep grow model from NGC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# model name from NGC is clara_train_deepgrow_aiaa_inference_only\n",
        "!curl -X PUT \"http://127.0.0.1/admin/model/clara_deepgrow\" \\\n",
        "     -H \"accept: application/json\" \\\n",
        "     -H \"Content-Type: application/json\" \\\n",
        "     -d \u0027{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}\u0027\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "The following cell will download the spleen model and load it into the AIAA server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "!curl -X PUT \"http://127.0.0.1/admin/model/clara_ct_seg_spleen_no_amp\" \\\n",
        "     -H \"accept: application/json\" \\\n",
        "     -H \"Content-Type: application/json\" \\\n",
        "     -d \u0027{\"path\":\"nvidia/med/clara_ct_seg_spleen_no_amp\",\"version\":\"1\"}\u0027"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "If you manually downloaded the MMAR you should run the command below to load the model \n",
        "```\n",
        "curl -X PUT \"http://127.0.0.1/admin/model/clara_ct_seg_spleen_amp\" \\\n",
        "     -F \"config\u003d@clara_ct_seg_spleen_amp_v1/config/config_aiaa.json;type\u003dapplication/json\" \\\n",
        "     -F \"data\u003d@clara_ct_seg_spleen_amp_v1/models/model.trt.pb\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Also if you have the MMAR structure zipped you could do \n",
        "```\n",
        "dataArg\u003d\"data\u003d@\"+AIAA_ROOT+\"/deepgrow_nifti.zip\"\n",
        "!curl -X PUT \"http://127.0.0.1/admin/model/clara_deepgrow_v2\" -F $dataArg\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Let us check the server and check that the model is uploaded. after running the cell below you should see the deep grow model name returned with the description "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!curl -X GET \"http://127.0.0.1:80/v1/models\" -H \"accept: application/json\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### AIAA Clients \n",
        "\n",
        "AIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n",
        "). \n",
        "NVIDIA has already implemented these APIs for a number of open source viewers:\n",
        "1. 3DSlicer. \n",
        "    1. Steps to install and setup slicer 3d [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n",
        "    2. Install by searching for nvidia in the plugin manager\n",
        "    3. Configure plugin. Add the AIAA server location and make sure the session is enabled\n",
        "       \u003cbr\u003e![side_bar](screenShots/SlicerConfig.png)\n",
        "    4. You should load a volume and start trying the spleen and deep grow model as shown below\n",
        "      \n",
        "\u003cbr\u003e![side_bar](screenShots/Slicer.png)\n",
        "\n",
        "2. MITK. You can download and install it [here](http://mitk.org/wiki/Downloads). \n",
        "Please make sure you install the release with nvidia AIAA.\u003cbr\u003e\n",
        "_Note_: Deep grow is not enabled yet in MITK \n",
        "\n",
        "### Stop AIAA server  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!stop_aas.sh"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}