{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Clara Train SDK Performance Comparisons  \n",
        "\n",
        "This is part one of the performance comparisons where we will use \n",
        "a sample test data to see different configurations. \n",
        "We will be using jupyter notebook plugins To monitor gpu utilization . \n",
        "Part two is the [Spleen Performance Notebook](PerformanceSpleen.ipynb) that runs performance on a representative dataset (spleen segmenation from the Decathlon challenge)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "By the end of this notebook you will understand different model training acceleration techniques available in Clara Train SDK:\n",
        "1. Batching by transform\n",
        "2. Smart Caching\n",
        "3. Smart caching + batching by transform\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Prerequisites\n",
        "- Familiarity with Clara Train main concepts. See [Getting Started Notebook](../GettingStarted/GettingStarted.ipynb)\n",
        "- 4 NVIDIA GPUs are recommended to see comparision side by side. \n",
        "If you only have a single gpu, you could either run the experiments sequentially or you could reduce the CNN model size to fit all experiments onto a single gpu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Resources\n",
        "You may watch the GTC Digital 2020 talks on Clara Train SDK \n",
        "- [S22563](https://developer.nvidia.com/gtc/2020/video/S22563)\n",
        "Clara train Getting started: cover basics, BYOC, AIAA, AutoML \n",
        "- [S22717](https://developer.nvidia.com/gtc/2020/video/S22717)\n",
        "Clara train Performance: Different aspects of acceleration in train V3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## GPU Dashboard\n",
        "\n",
        "This notebook comes with an extension called NVDashboard for displaying GPU utilization metrics by embedding inside jupyter notebooks. \n",
        "For more info please see https://github.com/rapidsai/jupyterlab-nvdashboard. This extension is already installed. \n",
        "From the left sidebar, please click on the third tab (System dashboards) and click on GPU Utilization and GPU Memory. \n",
        "Then you can drag the tab to the right side of screen to display these along with training performance notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Dataset \n",
        "This notebook uses a sample dataset (ie. a single image volume of the spleen dataset) provided in the package to train a small neural network for a few epochs. \n",
        "This single file is duplicated 32 times for the training set and 9 times for the validation set to mimic the full spleen dataset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Lets get started\n",
        "It is helpful to check the NVIDIA GPU resources available in the docker by running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# following command should show all gpus available \n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Run some imports and functions used in the notebook\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "def printFile(filePath,lnSt,lnOffset):\n",
        "    print (\"showing \",str(lnOffset),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n",
        "    lnOffset\u003dlnSt+lnOffset\n",
        "    !\u003c $filePath head -n \"$lnOffset\" | tail -n +\"$lnSt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# setting up MMAR root path \n",
        "MMAR_ROOT\u003d\"/claraDevDay/Performance/\"\n",
        "print (\"MMAR_ROOT is set to \",MMAR_ROOT)\n",
        "!ls $MMAR_ROOT\n",
        "!chmod 777 $MMAR_ROOT/commands/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Problem Setup\n",
        "In order to compare acceleration we use a single image file and duplicate it for our dataset. \n",
        "Let us check how this is done in the `dataset.json` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dataSetFile\u003dMMAR_ROOT+\"../../sampleData/dataset_28GB.json\"\n",
        "printFile(dataSetFile,2,13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "We will be comparing the following configurations:\n",
        "1. Baseline described in [trn1_base.json](./configDemo/trn1_base.json)\n",
        "2. Batching by transform (BT) described in [trn1_BT.json](./configDemo/trn1_BT.json)\n",
        "3. Smart caching described in [trn1_cache.json](./configDemo/trn1_cache.json)\n",
        "4. Smart cache + batching by transform described in [trn1_BT_cache.json](./configDemo/trn1_BT_cache.json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Experiment details\n",
        "\n",
        "#### Common parameters for all experiments:\n",
        "- Training dataset is same for all with training dataset size\u003d32\n",
        "- Batch size\u003d 4\n",
        "- Crop size \u003d 128x128x128\n",
        " \n",
        " **Note**: Since the pipeline acceleration affects number of iterations the goal is to keep \n",
        " the #epoch x iterations constant across all experiments.   \n",
        " \n",
        "#### Summary for all experiments:\n",
        " \n",
        " Parameter | Base Line | Batch by transform | Cache | BT + Cache \n",
        " --- | ---:| ---:| ----:| ---:\n",
        " Batch Size | 4 | 4| 4 | 2x2 \u003d4\n",
        " Cache Size / replacment | - | - | 32/0 | 32/0\n",
        " Itteration/epoch | 32/4\u003d8 | 32 |32/4\u003d4 | 32/2\u003d16 \n",
        " epochs |20 | 5 |40 | 10\n",
        " Epochs x Iteration | 20x8\u003d160 | 5 x 32 \u003d160 |40 x 4 \u003d160 | 10x16\u003d160\n",
        " Time for 10MB file size (speed up) | 1,778 (-) |  463(3.8x) |  344(5.2x)|  311(5.7x) \n",
        " Time for 30MB file size (speed up) | 3,972 (-) | 970 (4x) | 574 (7x)| 403 (10x) \n",
        " \n",
        "_Note:_ \n",
        "- Time and speed ups will vary depending on the dataset file size. Here we have spleen_8.nii.gz which is 10MB in size\n",
        "- Time and speed ups above were obtained using a V100 GPU with 32 GB while the dataset file was spleen_45.nii.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Examining each configuration\n",
        "In the following cells  examine how we set up each configuration and run them one at a time.  \n",
        "\n",
        "## Baseline\n",
        "You may see the contents of the full json configuration file `./configDemo/trn1_base.json` using `!cat /configDemo/trn1_base.json`\n",
        "below we focus on the pipeline section and the transformations "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "confFile\u003dMMAR_ROOT+\"/configDemo/trn1_base.json\"\n",
        "# To show the pipeline\n",
        "printFile(confFile,109,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# showing the transformations\n",
        "printFile(confFile,25,70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Running the cell below should result in low utilization as shown below\n",
        "\u003cbr\u003e ![a](screenShots/DemoBaseLine.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# This cell will train base line configuration. \n! $MMAR_ROOT/commands/train_FakeDS.sh trn1_base.json 0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Batch By Transform \n",
        "\n",
        "Typically data is moved from disk to memory then a crop is selected with an augmentation, then data is thrown away. \n",
        "With Batch by transform we take multiple batches from the same volume as shown below\n",
        "\n",
        "\u003cbr\u003e ![a](screenShots/BT.png)\n",
        " \n",
        "Here, the important things to change are:\n",
        "- The pipeline:\n",
        "    - Name `SegmentationImagePipeline` \n",
        "    - The pipeline parameter `batch_by_transform:true` as\n",
        "```\n",
        "\"image_pipeline\": {\n",
        "    \"name\": \"SegmentationImagePipeline\",\n",
        "    \"args\": {\n",
        "      \"data_list_file_path\": \"{DATASET_JSON}\",\n",
        "      \"data_file_base_dir\": \"{DATA_ROOT}\",\n",
        "      \"data_list_key\": \"training\",\n",
        "      \"output_crop_size\": [96, 96, 96],\n",
        "      \"output_batch_size\": 0,\n",
        "      \"batched_by_transforms\": true,\n",
        "      \"num_workers\": 2,\n",
        "      \"prefetch_size\": 0\n",
        "    }\n",
        "```    \n",
        "- selecting one of the batching transforms (`CropByPosNegRatio`, `FastCropByPosNegRatio`, `CropByPosNegRatioLabelOnly` ) \n",
        "and set the batch_size as \n",
        "```\n",
        "  {\n",
        "    \"name\": \"FastCropByPosNegRatio\",\n",
        "    \"args\": {\n",
        "      \"size\": [96,96,96],\n",
        "      \"fields\": \"image\",\n",
        "      \"label_field\": \"label\",\n",
        "      \"pos\": 1,\"neg\": 1,\n",
        "      \"batch_size\": 12,\n",
        "      \"batches_to_gen_at_once\": 48\n",
        "    }\n",
        "  },\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "confFile\u003dMMAR_ROOT+\"/configDemo/trn1_BT.json\"\n",
        "# To show the pipeline\n",
        "printFile(confFile,106,12)\n",
        "# showing the batch by transform \n",
        "printFile(confFile,74,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "\n",
        "Running cell below should result in better utilization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "! $MMAR_ROOT/commands/train_FakeDS.sh trn1_BT.json 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Smart Cache \n",
        "Typically data is moved from disk to memory for a single processing then thrown away. With smart Cache data is cached in memeory for next cycles as shown below\n",
        "\u003cbr\u003e ![a](screenShots/Cache.png) \u003cbr\u003e\n",
        "To minimize this overhead, one idea is to cache the result of the transformation chain and use it for training instead. \n",
        "However, we have to be careful to only cache results that are deterministic. \n",
        "Non-deterministic transforms like RandomRotate still need to be applied. \n",
        "Note: Epoch now is when we go over all data in the cache and not all available data. User should increase the number of epochs to compensate.\n",
        "\n",
        "Here, the important things to change are:\n",
        "- The pipeline:\n",
        "    - Name `SegmentationImagePipelineWithCache` \n",
        "    - Setting parameter `batch_by_transform:false`\n",
        "    - Setting parameter `num_cache_objects` and `replace_percent` as \n",
        "```\n",
        "\"image_pipeline\": {\n",
        "    \"name\": \"SegmentationImagePipelineWithCache\",\n",
        "    \"args\": {\n",
        "      \"data_list_file_path\": \"{DATASET_JSON}\",\n",
        "      \"data_file_base_dir\": \"{DATA_ROOT}\",\n",
        "      \"data_list_key\": \"training\",\n",
        "      \"output_crop_size\": [96, 96, 96],\n",
        "      \"output_batch_size\": 12,\n",
        "      \"batched_by_transforms\": false,\n",
        "      \"num_workers\": 4,\n",
        "      \"prefetch_size\": 24,\n",
        "      \"num_cache_objects\": 32,\n",
        "      \"replace_percent\": 0      \n",
        "    }\n",
        "```      \n",
        "- Selecting a **NON batching** transform for cropping `FastPosNegRatioCropROI` or `randomcrop`\n",
        "\n",
        "For more info on how smart cache works and these parameters, \n",
        "please see the [smart cache documentation](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v3.0/nvmidl/additional_features/smart_cache.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "confFile\u003dMMAR_ROOT+\"/configDemo/trn1_cache.json\"\n",
        "# To show the pipeline\n",
        "printFile(confFile,108,12)\n",
        "# showing the cropping transorm \n",
        "printFile(confFile,74,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Running the cell below should result in better utilization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "! $MMAR_ROOT/commands/train_FakeDS.sh trn1_cache.json 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Smart Cache + Batch by transform \n",
        "\n",
        "Problem with batch by transform is that it gets all crops from the same volume here we configure it to take crops from different volumes as shown below\n",
        "\u003cbr\u003e ![a](screenShots/Cache_BT.png) \n",
        "Here, the important things to change are:\n",
        "- The pipeline:\n",
        "    - Name `SegmentationImagePipelineWithCache` \n",
        "    - Setting parameter **`batch_by_transform:true`**\n",
        "    - Setting parameter `num_cache_objects` and `replace_percent` as \n",
        "```\n",
        "\"image_pipeline\": {\n",
        "    \"name\": \"SegmentationImagePipelineWithCache\",\n",
        "    \"args\": {\n",
        "      \"data_list_file_path\": \"{DATASET_JSON}\",\n",
        "      \"data_file_base_dir\": \"{DATA_ROOT}\",\n",
        "      \"data_list_key\": \"training\",\n",
        "      \"output_crop_size\": [96, 96, 96],\n",
        "      \"output_batch_size\": 0,\n",
        "      \"batched_by_transforms\": true,\n",
        "      \"num_workers\": 4,\n",
        "      \"prefetch_size\": 0,\n",
        "      \"num_cache_objects\": 32,\n",
        "      \"replace_percent\": 0      \n",
        "    }\n",
        "```      \n",
        "- Selecting a batching transform for cropping \n",
        "(`CropByPosNegRatio`, `FastCropByPosNegRatio`, `CropByPosNegRatioLabelOnly` ) as \n",
        "```\n",
        "  {\n",
        "    \"name\": \"FastCropByPosNegRatio\",\n",
        "    \"args\": {\n",
        "      \"size\": [96,96,96],\n",
        "      \"fields\": \"image\",\n",
        "      \"label_field\": \"label\",\n",
        "      \"pos\": 1,\"neg\": 1,\n",
        "      \"batch_size\": 12,\n",
        "      \"batches_to_gen_at_once\": 48\n",
        "    }\n",
        "  },\n",
        "```  \n",
        "- Adding a batch_transforms section \n",
        "```\n",
        "  \"batch_transforms\": [\n",
        "    {\n",
        "      \"name\": \"MergeBatchDims\",\n",
        "      \"args\": {\n",
        "        \"fields\": [\"image\", \"label\"]\n",
        "      }\n",
        "    }\n",
        "  ],\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "confFile\u003dMMAR_ROOT+\"/configDemo/trn1_BT_cache.json\"\n",
        "# To show batch_transforms section\n",
        "printFile(confFile,106,8)\n",
        "# showing the batch by transform \n",
        "printFile(confFile,73,10)\n",
        "# To show the pipeline\n",
        "printFile(confFile,114,12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Running the cell below should result in the best utilization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "! $MMAR_ROOT/commands/train_FakeDS.sh trn1_BT_cache.json 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Running all configurations together\n",
        " \n",
        "The image below shows how to monitor multiple concurrent jobs. \n",
        "This allows you to compare multiple training configurations running simultaneously and compare the GPU utilizations. \n",
        "We assume you have 4 gpus and will run each configuration on a different gpu  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Running cell below should result in Utilization similar to \n",
        "\u003cbr\u003e ![a](screenShots/DemoAll4Running.png)\n",
        "\n",
        "The cell below defines helper functions to run each shell script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def f1():\n",
        "    # will show performance in Black color \n",
        "    !/$MMAR_ROOT/commands/train_FakeDS.sh trn1_BT_cache.json 3\n",
        "def f2():\n",
        "    # will show performance in Green color \n",
        "    !/$MMAR_ROOT/commands/train_FakeDS.sh trn1_cache.json 2\n",
        "def f3():\n",
        "    # will show performance in RED color \n",
        "    !/$MMAR_ROOT/commands/train_FakeDS.sh trn1_BT.json 1\n",
        "def f4():\n",
        "    # will show performance in Blue color \n",
        "    !/$MMAR_ROOT/commands/train_FakeDS.sh trn1_base.json 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "The cell below will run all configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "\n",
        "from multiprocessing import Process\n",
        "p1 \u003d Process(target\u003df1)\n",
        "p2 \u003d Process(target\u003df2)\n",
        "p3 \u003d Process(target\u003df3)\n",
        "p4 \u003d Process(target\u003df4)\n",
        "\n",
        "p1.start()\n",
        "p2.start() \n",
        "p3.start()\n",
        "p4.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "if you wish to suppress the output you could run the following cell instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "trainscript\u003dMMAR_ROOT+\"/commands/train_FakeDS.sh\"\n",
        "d \u003d subprocess.Popen([trainscript,\"trn1_BT_cache.json\",\"3\"]) # Black \n",
        "c \u003d subprocess.Popen([trainscript,\"trn1_cache.json\",\"2\"]) # Green\n",
        "b \u003d subprocess.Popen([trainscript,\"trn1_BT.json\",\"1\"]) #Red\n",
        "a \u003d subprocess.Popen([trainscript,\"trn1_base.json\",\"0\"]) # Blue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Exercise\n",
        "1. You could test out the BT+cache old implementation in clara train V2 by running the \n",
        "[trn1_BT_cache_TrnV2.json](configDemo/trn1_BT_cache_TrnV2.json). \n",
        "Which has the following important changes\n",
        "    - Use pipeline `SegmentationImagePipelineWithCache`\n",
        "    - Set `batch_by_transform \u003d true`\n",
        "    - Use one of the cropping transforms as FastCropByPosNegRatio\n",
        "    - No batch merge section \n",
        "2. You may redo this comparision on a real dataset such as the spleen segmentation problem \n",
        "or you move through even more optimization in the [Spleen Performance Notebook](PerformanceSpleen.ipynb)\n",
        "3. You may change the cache size and replacements and see its effects. you can follow the table below \n",
        "\n",
        "**Summary for all experiments:**\n",
        " \n",
        " Parameter | Base Line | Batch by transform | Cache | BT + Cache \n",
        " --- | ---:| ---:| ----:| ---:\n",
        " Batch Size | 4 | 4| 4 | 2x2\u003d4\n",
        " Cache Size / replacement | - | - | 16/0.1 | 16/0.1\n",
        " Iteration/epoch | 32/4\u003d8 | 32 |16/4\u003d4 | 16/2\u003d8\n",
        " epochs |20 | 5 |40 | 20\n",
        " Epochs x Iteration | 20x8\u003d160 | 5 x 32 \u003d160 |40 x 4 \u003d160 | 10x16\u003d160 \n",
        "\n",
        "\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}